{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsEj39ikmhxJ"
      },
      "source": [
        "# **Answering the questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRvZKeWImkFi"
      },
      "source": [
        "‚úîÔ∏è Answer the questions below (briefly):\n",
        "\n",
        "üåàBased on the provided template, describe the format of the input file (sdf file).\n",
        "\n",
        "- Structure Data Format (SDF) is a file format commonly used in chemistry for storing and exchanging molecular structures, properties, and related data.\n",
        "- Can contain information about individual molecules or collections of molecules\n",
        "- it include information about the positions of individual atoms in a chemical molecule as well as the connections between them\n",
        "\n",
        "\n",
        "üåàWhat are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?\n",
        "\n",
        "- data :The data is in a tokenized form and includes the nodes of the chemical molecule.The batch_size refers to the number of samples in a batch, while max_len_nodes indicates the padded length of the tokenized nodes.\n",
        "\n",
        "- edge : it contains information about the connections between atoms.\n",
        "- node2graph:It is The segmented mean input tensor contains information about segmented IDs.\n",
        "\n",
        "\n",
        "üåàFor each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?\n",
        "\n",
        "- dim of gnn_out is (batch_size_node_dimension, hidden layers), where batch_size_node_dimension refers to the dimension of the input data vector (i.e., the dimension of the tokenized vector for the entire batch) and hidden layers represents the aggregation output of the model for each hidden layer.\n",
        "- dim of avg is determined by calculating the segmented mean of gnn_out using the segmented IDs. Specifically, the output of gnn_out is (tokenized_vector_dimension, hidden_layers) for each sample in the batch_size, and a segment ID is assigned to each sample.\n",
        "\n",
        "\n",
        "üåàWhat is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n",
        "\n",
        "- segment_mean: calculates the average of data that have the same segmented ids.\n",
        "\n",
        "- reduce_mean: computes the mean value of elements across the specified dimensions of a tensor.\n",
        "- The shape of the \"pred\" tensor is (num_of_graphs, num_of_units in the output layer), where the first dimension represents the number of graphs and the second dimension is the number of units in the output layer, which is 1.\n",
        "\n",
        "\n",
        "üåàWhat is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n",
        "\n",
        "- By increasing the number of trainable parameters in the network, the complexity of the model will increase, allowing it to better distinguish features in each node through a more complex hyperplane. This increased complexity can lead to more accurate results for node classification.\n",
        "- the number of layers used in the template was the default number which is 4 layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sudgalm0ni5u"
      },
      "source": [
        "# **Problem Formulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sr1vYFGqDfF"
      },
      "source": [
        "## Problem Definition\n",
        "\n",
        "- Our goal is to create a model that can predict the effectiveness of chemical compounds against non-small cell lung cancer using complex chemical structured data. The model will be designed to distinguish between compounds that are effective and those that are not.\n",
        "- input data consists of 2 feature sets: the first set represents the nodes, and the second set represents the edges between these nodes.\n",
        "- output is if this chemical compound is effective 1 or not 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOAxa629rZUE"
      },
      "source": [
        "## Data mining function\n",
        "\n",
        "- classification and prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUwkhqIrZWr"
      },
      "source": [
        "## Challenges\n",
        "\n",
        "- Our dataset is stored in SDF files, which are chemical files that represent each sample as nodes and the edges that connect these nodes, along with the corresponding output. Therefore, we require a specialized function to extract the relevant information from these files.\n",
        "\n",
        "- The data is imbalanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4otjvZIvrj44"
      },
      "source": [
        "## Model impact\n",
        "\n",
        "- Addressing this medical problem has the potential to make significant progress in the field of medicine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9YtFnFzro2i"
      },
      "source": [
        "## The ideal solution\n",
        "\n",
        "- Trial \"9\" GNN-FiLM Using RandomOverSample was the highest Test Accuracy = 88.37% with those Hyperparameters\n",
        "- hidden_dim = 32, num_layers = 6, film_parameter_MLP_hidden_layers = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCpYUw7KsCXV"
      },
      "source": [
        "# **Importing Libraries and check data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTGgVGETslw1"
      },
      "outputs": [],
      "source": [
        "#!pip install --quiet networkx\n",
        "#!pip install --quiet tf2_gnn\n",
        "#!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCCXeIJ5mefQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np   \n",
        "from tqdm.notebook import tqdm\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "#importing libraries for displaying network of molecule\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "#for deep Graph Neural Network\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
        "#importing tensorflow and other libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import math\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVR4phKHsG_A"
      },
      "outputs": [],
      "source": [
        "def read_sdf(file):\n",
        "  #opening the file\n",
        "  with open(file, 'r') as rf:\n",
        "    content = rf.read()\n",
        "    samples = content.split('$$$$')\n",
        "    \n",
        "    def parse_sample(s):\n",
        "        lines = s.splitlines()\n",
        "        links = []\n",
        "        nodes = []\n",
        "        label = 0\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "            if l.startswith('    '):\n",
        "                feature = l.split()\n",
        "                node = feature[3]\n",
        "                nodes.append(node)\n",
        "            elif l.startswith(' '):\n",
        "                lnk = l.split()\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "                    links.append((   \n",
        "                        int(lnk[0])-1,   #first atom\n",
        "                        int(lnk[1])-1, # zero-based index #second atom\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label #returning nodes, links and label\n",
        "    #parse_sample for each molecule\n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fed583ccf6af4e378edc72a61d6af690",
            "d9bea941346e4c3bb3aab74ee452a751",
            "a5f274eb69c9493eadadd21b60974923",
            "58358e0c85a149cbaa5448717c64b4b3",
            "88d83feb7c2640e3915e2a03654e21e9",
            "8fd947e6cd3c43fcb31678391ecea122",
            "18c2b9e8f0f748998720e71ca7845fcc",
            "dead3d8ff34e4062bc294dc5bc9125bd",
            "a0e40a02cb1a47fb9da41f9b96e679ef",
            "0327c0dad8fc4b9aa5a93993c0363319",
            "efd45c231402417a8f98c852e3bc38c6",
            "926dd136cac14f919d3275a48561c8a9",
            "a4960bfa9f014222b805bde80788b375",
            "5b89e71fc8d043a392b61ea493b79b44",
            "f8683b3a53694c82ace06cab4b5b5e91",
            "ee6314ce05c04ee885fd220883124499",
            "5fb4cec0034d4c1db2e0e84b0ac62ee4",
            "0f1fa67b224e402d97557584d3268080",
            "0beb302c2b9746329f7ec3a98926ba82",
            "4100bdce902f40ecb70c6ffa920ccb27",
            "8afc8dad8e1942eca6cbd5c253e45464",
            "eaa20e722483401ba3819c0661f3ce55",
            "01e06549ec85462696ec4403a1e6f2b9",
            "f486db7fd98f413a8ddb35317319e6de"
          ]
        },
        "id": "HmcSbIhdsHBX",
        "outputId": "a29fe63e-8a89-448b-9452-00da61117096"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01e06549ec85462696ec4403a1e6f2b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f486db7fd98f413a8ddb35317319e6de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#reading train.sdf file\n",
        "training_set = read_sdf('train.sdf')\n",
        "testing_set = read_sdf('test_x.sdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDIUd6FJsHDg",
        "outputId": "0ac989ae-39f9-44c1-d20d-49f0f24e026e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_16828/852145860.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.unique(np.array(training_set)[:,2],return_counts=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=object), array([23806,  1218], dtype=int64))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(np.array(training_set)[:,2],return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504362qJsHFw"
      },
      "outputs": [],
      "source": [
        "#splitting the train data\n",
        "training_set, validation_set = train_test_split(training_set, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL7bQTmnsHH3",
        "outputId": "91992d13-840e-46df-e21d-4eecef0f7c11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_16828/852145860.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.unique(np.array(training_set)[:,2],return_counts=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=object), array([19052,   967], dtype=int64))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(np.array(training_set)[:,2],return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLOJzR94t5ZL"
      },
      "outputs": [],
      "source": [
        "colors = cm.rainbow(np.linspace(0, 1, 50))\n",
        "\n",
        "def visualize(sample):\n",
        "  #initiating an instance of Graph\n",
        "  G=nx.Graph()\n",
        "  #all atoms as nodes\n",
        "  nodes = sample[0]\n",
        "  #all connections as edges\n",
        "  edges = sample[1]\n",
        "  #empty dictionary for labels for the all nodes\n",
        "  labeldict={}\n",
        "  #empty array for each node color\n",
        "  node_color=[]\n",
        "  for i,n in enumerate(nodes):\n",
        "    #adding node to the graph each node as (0,1,2,3..)\n",
        "    G.add_node(i)\n",
        "    #dictionary building with [key,value] as [0:'C']\n",
        "    labeldict[i]=n\n",
        "    #color coding\n",
        "    node_color.append(colors[hash(n)%len(colors)])\n",
        "\n",
        "  # a list of nodes:\n",
        "  for e in edges:\n",
        "    #adding egde to the graph from one connection to other connection\n",
        "    G.add_edge(e[0], e[1]) \n",
        "\n",
        "  #drawing the graph with labels for nodes as atoms and connections as edges    \n",
        "  nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "  #draw the graph\n",
        "  plt.show()\n",
        "  #returns graph\n",
        "  return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "TqsMTZTxt5bq",
        "outputId": "29f97d45-a3a6-4f48-ba45-eb683430895e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x2411314d400>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#displaying one sample\n",
        "plt.clf()\n",
        "visualize(training_set[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju9rslKkunTm"
      },
      "source": [
        "# **Part 1: Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oI9qv8vu_Iz"
      },
      "outputs": [],
      "source": [
        "max_vocab = 500\n",
        "# maximum length of the tokenized vector\n",
        "max_len = 100 \n",
        "\n",
        "# build vocabulary from training set only for nodes characters\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "\n",
        "#training tokenizer\n",
        "tokenizer = Tokenizer(num_words = max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7_X0jbgu_LJ"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "def prepare_single_batch(samples):\n",
        "  #nodes characters array\n",
        "  sample_nodes = [s[0] for s in samples]\n",
        "  #tokenizing the sample nodes\n",
        "  sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
        "  #pad_sequences for each sample node with post padding and post truncating \n",
        "  sample_nodes = pad_sequences(sample_nodes, padding='post', truncating = 'pre')\n",
        "  #maximum length of nodes \n",
        "  max_nodes_len = np.shape(sample_nodes)[1]\n",
        "  #defining edges\n",
        "  edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
        "  edges = [e for e in edges if len(e) > 0]\n",
        "\n",
        "  #array definition for segmented_ids\n",
        "  node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
        "  \n",
        "  #reshaping as 1 vector\n",
        "  all_nodes = np.reshape(sample_nodes, -1)\n",
        "  #concatenating all the edges as size [total_edges ,2]\n",
        "  all_edges = np.concatenate(edges)\n",
        "\n",
        "  node_to_graph = np.reshape(node_to_graph, -1)\n",
        "  #returns a dictionary of features(data,edges,node2grah) and label\n",
        "  return {\n",
        "      'data': all_nodes,\n",
        "      'edges': all_edges,\n",
        "      'node2grah': node_to_graph,\n",
        "  }, np.array([s[2] for s in samples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxJOtG0wvKN-"
      },
      "outputs": [],
      "source": [
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:\n",
        "      dataset = list(dataset)\n",
        "      if shuffle:\n",
        "        #randomly shuffling\n",
        "        random.shuffle(dataset)\n",
        "      \n",
        "      #length of dataset\n",
        "      l = len(dataset)\n",
        "      #for creating batches from given dataset\n",
        "      for ndx in range(0, l, batch_size):\n",
        "        #creating batch samples with given batch_size\n",
        "        batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
        "        #returning a generator with prepared batches\n",
        "        yield prepare_single_batch(batch_samples)\n",
        "        \n",
        "      if not repeat:\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpxtFrRxvKQd",
        "outputId": "9123e42e-73dd-4bbb-d062-50becb2ba2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "Shape is (228,)\n",
            "edges\n",
            "Shape is (126, 2)\n",
            "node2grah\n",
            "Shape is (228,)\n",
            "label [0 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)        \n",
        "        print(\"Shape is \"+str(np.shape(v)))\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmYsFtefvWvE"
      },
      "source": [
        "# **Part 2: Building The Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W30yR6DBujwV"
      },
      "source": [
        "## Trial 1 Using Default Hyperparameters And not fixing the Data Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n1p_sTlt5eS",
        "outputId": "24aefc1c-eb14-486f-e258-298e7581c26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 80)           40000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           24384       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,417\n",
            "Trainable params: 64,417\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Input layer (tokenized text)\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different.it is the total number of edges in this batch\n",
        "\n",
        "#Input for edge data\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "#Input for node2graph ids\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "#embedding over data with each token as a vector\n",
        "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
        "\n",
        "\n",
        "# number of graphs\n",
        "#calculating number of graphs\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32\n",
        "gnn_layer = GNN(params)  \n",
        "#outpur shape: [data_dimension,hidden layers]\n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "#output shape: [batch_size,1]\n",
        "print('pred:', pred)\n",
        "\n",
        "#Building The Model \n",
        "#inputs is dictionary of data, edges, node2graph\n",
        "#output: prediction value from dense layer\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpx71cezt5gq"
      },
      "outputs": [],
      "source": [
        "# Compile the model by using my adam optimizer and BinaryCrossentropy loss\n",
        "model.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9goEt1et5jF",
        "outputId": "2b6b2d75-8ac5-4e2b-ede2-507b77d896df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "626/626 [==============================] - 9s 11ms/step - loss: 0.2523 - auc: 0.4823 - val_loss: 0.2039 - val_auc: 0.6819\n",
            "Epoch 2/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1927 - auc: 0.6100 - val_loss: 0.1822 - val_auc: 0.6764\n",
            "Epoch 3/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1874 - auc: 0.6451 - val_loss: 0.1819 - val_auc: 0.7160\n",
            "Epoch 4/30\n",
            "626/626 [==============================] - 7s 12ms/step - loss: 0.1863 - auc: 0.6484 - val_loss: 0.1813 - val_auc: 0.7083\n",
            "Epoch 5/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1835 - auc: 0.6713 - val_loss: 0.1795 - val_auc: 0.7297\n",
            "Epoch 6/30\n",
            "626/626 [==============================] - 7s 12ms/step - loss: 0.1816 - auc: 0.6849 - val_loss: 0.1673 - val_auc: 0.7482\n",
            "Epoch 7/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1798 - auc: 0.7003 - val_loss: 0.1726 - val_auc: 0.7445\n",
            "Epoch 8/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1778 - auc: 0.7180 - val_loss: 0.1733 - val_auc: 0.7663\n",
            "Epoch 9/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1747 - auc: 0.7344 - val_loss: 0.1777 - val_auc: 0.7955\n",
            "Epoch 10/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1748 - auc: 0.7307 - val_loss: 0.1736 - val_auc: 0.7708\n",
            "Epoch 11/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1706 - auc: 0.7548 - val_loss: 0.1672 - val_auc: 0.7697\n",
            "Epoch 12/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1727 - auc: 0.7409 - val_loss: 0.1661 - val_auc: 0.7926\n",
            "Epoch 13/30\n",
            "626/626 [==============================] - 7s 12ms/step - loss: 0.1719 - auc: 0.7453 - val_loss: 0.1626 - val_auc: 0.7920\n",
            "Epoch 14/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1702 - auc: 0.7565 - val_loss: 0.1671 - val_auc: 0.7999\n",
            "Epoch 15/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1710 - auc: 0.7524 - val_loss: 0.1674 - val_auc: 0.7877\n",
            "Epoch 16/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1706 - auc: 0.7509 - val_loss: 0.1622 - val_auc: 0.8096\n",
            "Epoch 17/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1702 - auc: 0.7549 - val_loss: 0.1661 - val_auc: 0.7899\n",
            "Epoch 18/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1689 - auc: 0.7650 - val_loss: 0.1700 - val_auc: 0.7904\n",
            "Epoch 19/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1694 - auc: 0.7641 - val_loss: 0.1641 - val_auc: 0.7902\n",
            "Epoch 20/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1676 - auc: 0.7716 - val_loss: 0.1642 - val_auc: 0.7948\n",
            "Epoch 21/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1685 - auc: 0.7671 - val_loss: 0.1701 - val_auc: 0.7765\n",
            "Epoch 22/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1676 - auc: 0.7662 - val_loss: 0.1690 - val_auc: 0.7687\n",
            "Epoch 23/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1667 - auc: 0.7736 - val_loss: 0.1625 - val_auc: 0.8060\n",
            "Epoch 24/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1650 - auc: 0.7783 - val_loss: 0.1676 - val_auc: 0.7837\n",
            "Epoch 25/30\n",
            "626/626 [==============================] - 7s 11ms/step - loss: 0.1657 - auc: 0.7754 - val_loss: 0.1652 - val_auc: 0.8066\n",
            "Epoch 26/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1664 - auc: 0.7739 - val_loss: 0.1657 - val_auc: 0.7962\n",
            "Epoch 27/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1640 - auc: 0.7864 - val_loss: 0.1660 - val_auc: 0.8051\n",
            "Epoch 28/30\n",
            "626/626 [==============================] - 6s 10ms/step - loss: 0.1642 - auc: 0.7825 - val_loss: 0.1641 - val_auc: 0.8125\n",
            "Epoch 29/30\n",
            "626/626 [==============================] - 7s 10ms/step - loss: 0.1646 - auc: 0.7802 - val_loss: 0.1612 - val_auc: 0.8002\n",
            "Epoch 30/30\n",
            "626/626 [==============================] - 7s 10ms/step - loss: 0.1638 - auc: 0.7856 - val_loss: 0.1584 - val_auc: 0.8108\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "hist = model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uR4Cs_VwB-P"
      },
      "source": [
        "- 78.56% training AUC\n",
        "- 81.08% validation AUC\n",
        "It's a good start but we Still can improve it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF9avmoRwY1q"
      },
      "source": [
        "## Trial 2 Using **Upsampling** to fix the Data Imbalance With Default Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cd7feacd7421452a9cbbc55019d5fe58"
          ]
        },
        "id": "Ajpz0SGM-VJe",
        "outputId": "6f45bac7-7895-4bce-fce7-577e7450144c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7feacd7421452a9cbbc55019d5fe58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_set = read_sdf('train.sdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrCUqGzzwC6G",
        "outputId": "a18030e6-544a-4fea-91b3-80eb55704376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_9620/4094584240.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  unique, counts = np.unique(np.array(training_set)[:,2], return_counts=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "unique, counts = np.unique(np.array(training_set)[:,2], return_counts=True)\n",
        "maxCount=23806\n",
        "sns.barplot(x=unique, y=counts)\n",
        "plt.xlabel('target')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Counts of target')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCTMNMLLxNMg",
        "outputId": "b9f37482-4cf0-4c81-f04c-4b2f7f58679f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_9620/795063482.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = pd.DataFrame(np.array(training_set)[:,:], columns = ['0', '1', 'target'])\n"
          ]
        }
      ],
      "source": [
        "#convert the data from List to DataFrame to make upsampling\n",
        "data = pd.DataFrame(np.array(training_set)[:,:], columns = ['0', '1', 'target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7ikq89kx77s"
      },
      "outputs": [],
      "source": [
        "resampling = data.copy()  #take a copy of dataframe\n",
        "class_0 = resampling[resampling['target']==0]   # all rows has target zero\n",
        "class_1 = resampling[resampling['target']==1]   # all rows has target one\n",
        "class_1_after = resample(class_1, replace=True,n_samples = maxCount)   \n",
        "data_upsampled = pd.concat([class_0, class_1_after])    #add the new rows "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxbKUmPdx9Zk",
        "outputId": "1afead8c-fa83-4a19-fb85-e357e7753dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    23806\n",
              "1    23806\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_upsampled['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl3P60ETx-8F",
        "outputId": "5be76d6d-e966-4759-fab4-18464db11615"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x='target', data=data_upsampled)\n",
        "plt.xlabel('Target')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Counts of Target')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYrn-bXlyAAG"
      },
      "outputs": [],
      "source": [
        "#converting the upsampled DataFrame into list\n",
        "training_set = data_upsampled.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfd9PzGGyCrH"
      },
      "outputs": [],
      "source": [
        "training_set, validation_set = train_test_split(training_set, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp1HBSKwyErw",
        "outputId": "df3c0b16-c1c1-4c28-aeed-d2fb0727333c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABFaElEQVR4nO3dd3xUZdbA8d+dll6ooYQmoRmULobeQQUFBEFZkFgQRdHVldXX1XUVXVdXsQvqEkFABcGgKAiIgERAehGQqvQOgSTT575/XAkkM0lmQjIlc76fTxTvvXPnTCQ592nnUVRVVRFCCCHChC7QAQghhBD+JIlPCCFEWJHEJ4QQIqxI4hNCCBFWJPEJIYQIK5L4hBBChBVJfEIIIcKKJD4hhBBhRRKfEEKIsCKJTwghRFiRxCeEECKsSOITQggRViTxCSGECCuS+IQQQoQVSXxCCCHCiiQ+IYQQYUUSnxBCiLAiiU8IIURYkcQnhBAirEjiE0IIEVYk8QkhhAgrhkAH4K3zR+DYdrBcAGMkJNSC5NagKIGOTAghRCgJ6sTncsHeFbDibfh9NegjQHVpyU51QVQidHkY2twJUQmBjlYIIUQoUFRVVQMdhCc5p+CjQXD2d7DlFn2dMRoUYMQn0LS3n4ITQggRsoIy8V08CW93g5zT4LJ79xpjFAx9D1oMKtfQhBBChLigm9zitMOHt2otPm+THoDdDHPGwcH15RebEEKI0Bd0ie/Xb+H8YXA53M/tsM1i2sW2TDofy3vZNZmTcxOHHavyz9vN8N0//RisEEKIkBN0k1uWv+l5TG+d5Q3WWl+hT9Rk6hv7osfEAcci9tjnk2zolH/doY1w9g+oXM9/MQshhAgdQTXGd2IXvN0dHJaCx61qNu9n1+am6AyamoYWew+9EdLugwEvl2OgQgghQlZQdXX+vtbzurwjjtU4sNDYWPLMFacd9iwv+9iEEEJUDEGV+CzZ4PQwtmdWzxCtVEWneNcza7lQxoEJIYSoMIIq8elNoPMQUZRShTz1NC7VQ1b0dB9jGQcmhBCiwgiqxBeX5Dlp1TakYSCSPfZMr+8jhBBCeBJUia9pb3A53Y9HKAl0inyBJeZx7LFlYlfzcKp29tsXstw8oeC1sXBjup8CFkIIEXKCajlDRCy0HAobZrmv42sX+TjRuiR+tk5kQd4ITEocSfo2pEU+U+A6FbjuNv/FLIQQIrQE1XIG0JY0vNMd7JaSry3MEAE33gsDXir7uIQQQlQMQdXVCZDUFLo9rhWf9oXOAJXqQd//K5+4hBBCVAxBl/gAev5NG6czRnl3vSECKteHB74BU0y5hiaEECLEBV1X55XWfwaLXgBrDthy3M8bo7V9+VoOhltfgYg4/8cohBAitAR14gNtM9p9K7XNaI9u1ep4OrFh1Z9m8LO1aDNcNqEVQgjhvaBPfJ6sX7+e++67j82bNwc6FCGEECEmJBNfTk4O1atX5+LFi+j1+kCHI4QQIoQE5eSWksTGxpKUlMT+/fsDHYoQQogQE5KJDyA1NZVff/010GEIIYQIMSGb+K699lp27NgR6DCEEEKEmJBNfNLiE0IIURqS+IQQQoSVkJzVCTKzUwghROmEbItPZnYKIYQojZBNfCDdnUIIIXwX0olPZnYKIYTwVUgnPmnxCSGE8FVIJ75rr71WEp8QQgifhOysTpCZnUIIIXwX0i0+mdkphBDCVyGd+EC6O4UQQvgm5BNfamqqzOwUQgjhtQqR+KTFJ4QQwlshn/ikq1MIIYQvQnpWJ8jMTiGEEL4xBDqAq6GqcGJzLLfEZvDeLRYiTTHEVIFm/eC628AYGegIhRBCBJuQbPE5bLAmA1a+A+bzYM11oVzRa2uKARS4YRR0Gw9xSQELVQghRJAJucRnzob/3Q7Hd4DdXPy1OiNExsGY+VCzuX/iE0IIEdxCKvHZzfBebzi5B5w2718XEQePLINqKeUXmxBCiNAQUolvzsOweS44LO7ndthmsc76BmeduzApcVTXtyQt8hmSDZ1QFEioDX/fDDqZ/yKEEGEtZCa35J0vOumts7zBWusr9ImaTH1jX/SYOOBYxB77fJINnVBV7fW7f4CmffwduRBCiGASMi2+le/C4pfdx/WsajbvZ9fmpugMmpqGFnuPBh1h7IJyDFIIIUTQC5kF7Ksme57McsSxGgcWGhsHlXiPQ+sh+2g5BCeEECJkhEziu3jc83GzeoZopSo6peReW0MEnDtUxoEJIYQIKSGR+JwOcLk8n4tSqpCnnsalOry6lzWnDAMTQggRckIi8ekNRc/GrG1Iw0Ake+yZXt0rMq7s4hJCCBF6QiLxAVSq4/l4hJJAp8gXWGIexx5bJnY1D6dqZ799IcvNEwpc67BClQZ+CFYIIUTQCpnlDJ0fhu+eBVue+7l2kY8TrUviZ+tEFuSNwKTEkaRvQ1rkM5cvUqBhZ4it5r+YhRBCBJ+QWc5gvQgvNim5TFlRTDEw+jMt+QkhhAhfIdPVGREHN9wNxijfX6szQGIyXNOp7OMSQggRWkIm8QHc8iIktwaDL9sNKS4iE+C+eaAo5RaaEEKIEBFSiU9vgHvnaN2VpuiSrzdEushRj9J24s8k1Cr/+IQQQgS/kBnju5LLBdvmw4q34eSuP9f55S/jUzHFKkTEQJeHwVxvOaPH3Mm6detITk4OZNhCCCGCQEgmvisd3wnbvtZKkW34ZRNKdA6jn+lMSjfQ/dmefeWVV5g/fz4rVqzAZDIFNF4hhBCBFfKJ70offPABmzdvZsqUKQWOq6rKoEGDSE5O5t133w1QdEIIIYJBSI3xlaRmzZocO3bM7biiKEybNo3vv/+emTNnBiAyIYQQwSIsEh9AQkICc+fO5bHHHmPbtm1+jkwIIUSwqFCJr0aNGhw/XsQ2DsD111/PpEmTuP3228nOzvZjZEIIIYJFhRrjs1qtxMXFYbFY0OmKzunjxo3j6NGjzJs3D+XPxX3mbNi1GHJOgdMOUQlQrz3UaOav6IUQQvhDhUp8AJUrV2b37t1UrVq1yGusVitdu3Zl0KBBjOr/d356D7Z8pa0TdNhAdYHeBKhQvTF0fRSa9we90X+fQwghRPmocIkvNTWVzz//nOuuu67Y6w4ePMSY1l/SSj8enHpczqKvNcVou0OM+VqKXAshRKirUGN8UPwElyttfLcOrQyP4LIVn/QAbLlwah+83Q1yz5RNnEIIIQKjwiW+kia4AKz9BNbPBJfV+12ZXHbIOQ0fD4aK1UYWQojwEjL78XmrpBafywnfvwR2D/v6AeywzWKd9Q3OOndhUuKorm9JWuQzJBs64bTB6X2wf5VsbySEEKGqwiW+GjVqcPjw4SLP7/4BHBbP59ZZ3mCt9RX6RE2mvrEvekwccCxij30+yQZtTyNbnlYjVBKfEEKEpgrX1VlSi2/F22DNcT9uVbNZZXmOXlHv0dg0GJMSg14xkmIcQPeo1y5fqMK+n+BC8b2pQgghglTYJb6jRRRtOeJYjQMLjY2DSnwPQwQc31HaCIUQQgRShUt8JU1usZs9HzerZ4hWqqJTSu79VV1guVDaCIUQQgRShUt8JbX4ilqEHqVUIU89jUt1eL7gCooOjL7sAi+EECJoVLjEl5CQgN1uJzc31+P52OqeX1fbkIaBSPbYM0t8D5cTEmpfRZBCCCECpsIlPkVRiu3uTLsPjFHuxyOUBDpFvsAS8zj22DKxq3k4VTv77QtZbp5Q4NrYqlCzeXlEL4QQorxVuMQHxXd3th1R9AL0dpGP0z3qDX62TuTd7GpMvlCHjdZ3aWQcmH+NKUar3flnbWshhBAhpsKt44PiJ7hEJ8L1t8GWTHBa3c+nmkaQahpR7P1bDb36GIUQQgRG2LX4AG57FRJrg87HtG+MgrtnQkTsVQYohBAiYMIy8UXGw4PfQZUG2po8bxij4M6PIKVrGQUphBAiICpk4vOmUHVcEjyyDNLuBVOs9lWYS7GhGJ2kdIUHF0LqLeUUsBBCCL+pkGN83m5NFBEL/V+Cvs/CtvmwdhrknACnQ2sVXkzYzr7IT3nly0l+iFoIIYQ/VMjE502L70rGSGg9TPu60tGjNUhN/QSr9RUiIrzsExVCCBHUKmRXp7ctvpLUqlWL5s2bs3Tp0jKISgghRDCokImvevXqnDlzBoej5PJjJRk6dChz5swpg6iEEEIEgwqZ+NCrNGvVkIOnd5PrPIdDtZf6VoMHD+brr7/GZrOVYYBCCCECRVHVouqYhJ4LjlP8Yd3ECftezHlmIiOi0Ol1qLiobmxI/YhWxBuKKNZZjI4dO/KPf/yDm266qRyiFkII4U8VIvFZXXlsyl1AjvMMLpyAp4+koENPrL4yrWIGEKGL9vr+kyZNYtu2bUydOrXMYhZCCBEYIZ/4LK4c1lz8ArtqQcVV4vUKOoxKJDfG3UGkLs6r9zh06BAtW7bk+PHjGI1F7GskhBAiJIT0cgaHamNdzlzsqhnVYyvPnYoLu2pmXc480uLuxKCYSnxNnTp1aNy4McuWLaNv375XG3ap5Z2HDZ/B4Y1gPq+tQ6zWBNrdBZXqBiwsIYQIKSHd4jtg2cA+y9o/uzc1o65/HqvFzrRNzxEZo629Wzj9Z5bNXs9rC8bnX6dDT8PI9jSIbOPVe73++uvs3LmTjz/+uGw/hBeO74Blb8Cv32q7Qly5i7zepB2r1x56PC4l1YQQoiQhO6tTVVX+sG4ukPQucTqcfDV5RbGvd+HkD+smvM37Q4YMITMzE7u99DNES2PLV/BuL9j6FTgsBZMegNMGDivsWwmf3AmLJha97ZIQQogQTnxnHAdxFrFMYegjPfny3WXkZOcVew+n6uC04w+v3q9evXo0bNiQ5cuX+xpqqW37GuaM05KdWvLwJXYzrPoAFv2r/GMTQohQFbKJ75T9AE48J75GrerSolMKX76zrNh7OLFzyn7A6/ccMmSI3xaznzkAX4x1b+EB7LDNYtrFtkw6H8t72TWZk3MThx2rALDnQdZHsPN7v4QphBAhJ2QTn9VVfGtu1NM3M//DlZw/ffGq7nOlS92dZVERpiSrPtCKZRe2zvIGy8yPkRbxf4xLOMHY+IO0iniIPfb5+dfY82Dpf8o9RCGECEmhO6tTKf50/Wtr0b5vKl+8uZS6jZOKuU0JN7pCgwYNqFevHitWrKBnz55ev85XdjOsnwWuQg1aq5rNKstz3BSdQWPT4PzjKcYBpBgHFLj2xE448RskNSm3MIW4asd3QNaHcHQrWHPAFKP9ne0wBuq0DnR0oqIK2RZfhFLyNugjn76ZRdN/5syx7KLv48NCdvBPd+f2bzwfP+JYjQMLjY2DSryH0wGr/T8BVQiv7Pwe3uqqTdxaNwMOb4JTe+DIZtg0B6YMgP+20/4sk7VEWQvZxFfD1BA9xS8mr31NNboMak3mFM8zPPUYSTI18ul9hw4dyldffYXT6T6btKyc2ge2XPfjZvUM0UpVdErJDXWXQ3uaFiKYqCos/jfMTNdaeXYzqIV+lFSX1l1/ai/MfUz7cpXfj5sIQyGb+BL1tTAqkSVeN+LJfljyPBeYNiqRVNLX8ul9r7nmGpKTk1m5cqVPr/OF+Zzn41FKFfLU07hU78YYrcUPbwrhd8teh5Xvep605Yk9DzbPgcwnyzcuEV5CdoxPURTqR7RmtyULF5cTwfStzxe4rnpyJRYcf8Pt9ToM1I9ohaJ4P8Z3yaXuzu7du/v8Wm9EVfJ8vLYhDQOR7LFn0sQ0pMT7RMaXcWBCXIU/1sGPbxQ9U3md9Q3OOndhUuKorm9JWuQzJBs6YTfDxi+gSU9IvcX/cYuKJ2RbfADJEanE6Cuh+PgxFHTE6BOpHZFaqvcdOnQo8+bNK7fuzuqNtEH+wiKUBDpFvsAS8zj22DKxq3k4VTv77QtZbp5Q4FqdAWqU7uMJUS6Wv6kVYSjM25nKy/7rv1hFxRbSJcsA7C4La3PmYHZdRPVQxaUwm8VOtCGBTpXvwqSLKvX7tmrVijfffJOuXcu+RpjdAi+kqNhyPbdGf7XNZL11EmedOzEpcSTp25AW+Qy1DR3yrzFEwmMroZpvQ5hClIucU/Dv67QqQ1eyqtm8n12bm6IzaGoaWuw9jFHwyI8yU1lcvZBu8QEYdZHcGDeMasb66NCjQ+/xukvn7KdNPNX/A5xWj5d5rbxmd6qqysLFX/MbM3AVsUA/1TSCu+PW89fEXMYlHGdI7LcFkh5AzeaS9ETw2PQlHpcg+TRT2Q5rPynz0EQYCvnEB2BQTLSMuZlO8aOoF9ESg2JC+XP/PQUFAybqRbSkU/woBqaOo2GDRowfP77kGxfjUneny+VFLTEvLVu2jLS0NP7xj38w9IWaRESXbgjWGAW9/15mYQlx1c7s99zN6etM5dP7yiE4EXZCdnKLJ5G6WBpFdSAlMg0nDpyqDb1iRI+xwCSWDz/8kLZt2zJ9+nRGjRpVqvdq2KAxzWPu4pUbc7Ecj8NuAYMJEmpBpweh1VBt2yBv/PLLLzzzzDMcOHCAF198kWHDhqHT6UitAbPu834GHIAxGro8DE16lepjCVEuLEXMML5yprI3yc/TMp/Scjnh5G5tFrWig5gqUDVF2+1EVGwhP8ZXWtu2baNHjx4sX76c1FTvZ4GoKix/C5ZPAovZCvYIt2tM0dp1be6C/hPBWMSqi+3bt/Pss8+ybt06nnvuOdLT0902uv31W/jsfnDY3Nc7FaBo79Ptr9Dzb/LDK4LLgmfgp/fdj18a47s5+hOvZipfewvcPePqYrl4UusyzZqijTnq/hwdcTogupL24NjmTohKuLr3EcGrQnR1lsZ1113Hq6++ytChQ8nJyfHqNU6HtvD2h9fAcgGPSQ/Alvdn2bGZ8EE/MBcqHLN//35GjRpFz5496dSpE3v27GHMmDEed3dPvQXGL4c2w7UJK8ZChWYMEdpXk15w75fQ60lJeiL41G5x9TOVXTorZw2bOH/+fKliUFVY/DK8cj38OAnyzmotSMsF7cueB9lHYNGLMLEp/DK9VG8jQkDYtvguSU9Px+FwMH369GLX9KkqfPkIbJnnW9ej3qT90D+wAE6dOcaLL77IF198wfjx4/nrX/9KfLz3i+0sF7RJAke2aD+0kXHaBJY2wyG+pvcxCeFv2kzlorsqvZmprBgc/Nb2bn7I+oa0tDQGDhzIrbfeSu3atUt8f1WFOQ/D1kwtwXnDGAXd/wo9ZfF8hRP2iS8vL4/27dvz6KOPct999xV53e4f4dO/aK25wopbfAtgiFRxtFzAx7+MJj09naeeeoqqVauW10cSIih9MOoQ+75JQo/J59cqOkjtDyOnQU5ODt9//z2ZmZl8++23NG7cmIEDBzJw4ECaNm3q8fVL/gMr3vY+6V1ijIJBk6DNMJ9DFkEs7BMfwK5du+jcuTNLliyhZcuWHq/5aBDsXe5+fJ3lDdZaX6FP1GTqG/uix8QBxyIOOVbSPeq1/OtckecZvzaHOnWTy+dDCBGkTp48yZNPPsnaH35jkGMVLqvvc+qMUfDQ91DruoLH7XY7K1asIDMzk8zMTGJjYxk0aBADBw6kXbt26HQ6cs/Cy9e6ryGEkh9aQRvre3YP6IsvDSxCSNiO8V2padOmvPXWWwwdOpQLFy64nT9/GH5f7f66S9sE9Yp6j8amwZiUGPSKkRTjgAJJDyBSn4hlvyQ9ET5cLhcfffQRzZs3p1q1aqzftZR7Zxsw+lg3whgFQ95xT3oARqORXr168e6773Lo0CE+/fRTdDod99xzD3Xq1OGhhx5i5rO7UXTuz/feVIwBbfbnjoW+xSyCm7T4rvDggw9y5swZvvjiiwLjfT+9D4tecH9i3G9fxNzc/jyRYPFqKnaL2+Eu2SpIhIFt27YxduxYXC4XkydPpkWLFvnn9mfBJ8O1yWKe1vZdojdppfeGT4bmA4q+rii7d+/mq68yOf7avZicVQqc86ViDEByK3hkme8xiOAkLb4rTJo0ib179/Lee+8VOJ591HM3iS+Lby/dR4iKLDc3lwkTJtCzZ09GjRpFVlZWgaQHcE1HeHI9dHtUK8geEaslOND+HRGrfXUcA0+sLl3SA2jcuDH3D59AjKmK2zlfKsaAtk+g07tNUUQIqFAL2K9WZGQkc+bMIS0tjfbt29OuXTvAc9ID3xffOj3vjiREhfDNN9/wyCOP0LlzZ7Zt20ZSUlKR18YlQe+noMff4Lcl2kJyywVtpnLl+nDtTdoynatlPn85qRY47uNDq86oxRdT+epjEoEnia+Qhg0b8sEHH3DHHXewceNGKlWqRExVtDqDhTqFfd0mKLqI7YaECCSXU9v9PO+ctgbU1womhw4dYvz48ezYsYOpU6fSo0cPr99bb9CS3LU3lTL4EihF9Gn5+tCKenmhuwh90tXpwe23385tt93G3XffjaqqXNNBq8ZSmC+Lb43R0Linnz6AEF7IOaVtDDuxCbzbSxt3yxgGb3WDfzeHnz5wL75wJbvdzuuvv06rVq1o1aoVW7du9Snp+UNsVc89LVc+tHpDdUFEXNnGJgJHJrcUwWaz0blzZ4YOHcoTT/yNfzcveozO222C/rFLyiCJwFNVrfrQj28AStETTIxR2rUDXoYb0wueW7NmDQ888ADVq1fn/fffp1Gj4N0K5PUb4eRv7se1pUj/oW/UFOob+6DDyB+OpRx0/Ei3qFcvX6hAs74w+jP/xSzKlyS+Yvzxxx/ccMMNzJs3D3VbRxa94FvVlksUPbS+A+7wUKtQCH9SVZj7GGz+0rcKJl0egT5Pw7lz53j66af5+uuvef311xk+fHixFY+CwYbPIfNvnqvGePPQaoqBe2ZDgw7urxehSRJfCRYsWMCDDz7ImpWbmDagKheOad0evoiIhUdXQpUG5ROjEN5a9jose6M0FUxUqg9ezb/n3s7gwYN56aWXSExMLJcYy5rdAi82Aqt3JXndVKoLf98sNXArEkl8XnjqqafYvHkzMz74jvd66rBc0CYEeMMYDffOkadFEXh55+GlZp67Nr2pYGJXLnLHN7u4sWM7/wVdRrZ/A58/4HuPjTEK7p8P9ULvI4tiyOQWL0ycOJG8vDymzPo341doT4CmEvbaM8VqszjHLpCkJ4LD+pmeWy3eVjCJiY4l6kRoZoDmA6D/S/hUNcYYBSOmStKriKTF56UjR47Qtm1bZs2aRdcu3dn9Ayx/Gw6t19Yb5ebmYjIZ0WGicn1tce51txW9F58Q/qSqWr3KC8cLHve1gknN6+CxleUUpB/s/B7mPqp1e3oa81N02s9sXA0YNlmSXkUlic8HS5YsYfTo0WzYsIEaNWoAcO6Qtgbq5X+9TocubbntL11JahLgQIUo5NwheL29e1efr2X3FB1MPAYG3zdYCBouF+xdoe3WsH+V9lCAS8Wh2mhxawRdH4E6bWRMryKTBew+6N27N/fffz933nknS5cuRa/XU6kOVKoDzozNRDaqJklPBKWyqmCiN4ElG2KrlW18/qTTQePu2hf8+TCgg+o1arD7v7upVi2EP5zwiozx+ejZZ59Fr9fz/PPPFzgeERGB1VpEbTMhAqyoqiNXVjDxiqotz6lIjFFgjFBITU3l119/DXQ4wg8k8flIr9czc+ZMpk6dyqJFi/KPS+ITwSymjCqYOB0VtwhD8+bN2b59e6DDEH4gia8UkpKSmDVrFqNHj+bQoUOAJD4R3OKqQ9WG7sd9KbsHWvdgRa1ZKS2+8CFjfKXUtWtXHn30UYYPH87y5csxmSLIPVCFGXfD72u1WWN6o/ak3f5uaPsXiE4MdNQinHV7DL563H0hd7vIx4nWJfGzdSIL8kYUqGByJVMMdB3vv3j9rXnz5syePTvQYQg/kFmdV8HlctG/f39S425Hv3Ygam4cisvkVtnlUs3D6wbArf+RXRpEYDis8EIjsF4s3esTasPT2yrubMdTp07RpEkTzpw5E/Rl2MTVka7Oq6DT6RjfbQ6uxXehZlcBh3vSA23WmMMCWzPhrS7a1HIh/M0Qoe1mXpq1pcYouOvjipv0AKpVq4bBYODYsWOBDkWUM0l8V2HdTFj1ZgwGvCsH4bRD9jGYfLNWPkoIf7v2Zuj+zEUceF+7yxgFwz+C+jeWY2BBQia4hAdJfKV08YRW8d1T7b8dtllMu9iWSedjeS+7JnNybuKwYxUAqlN77Xz3eQNClDuHw8FL827DdPMXxNcsuvSeomh7UFZuAPd9Bc1v8W+cgdK8eXOZ4BIGZHJLKa3J8Hxc2+PrFfpETaa+sS96TBxwLGKPfX5+wV+nHbZ/DebXKu7UcBGcJkyYgMlkYuL0keh0sG+lVnpv309/7jqiagvdm/aBro9A3XYVu3uzsNTUVH755ZdAhyHKmSS+UnA6IOtD9yr3VjWbVZbnuCk6g8amwfnHU4wDSDEOKHCtotOKBnd+yB8RCwEzZ85k/vz5rFu3Dr1eW5OQ0lX7Am37HkXRxgLDVfPmzZk6dWqgwxDlTLo6S+H3NeDyUOjiiGM1Diw0Ng4q8R52M6wtotUoRFnbtGkTjz32GJmZmVSuXNnjNcbI8E56oLX4duzYgcvl46abIqRI4iuFi8cBD4tAfK17mHOmbOMSwpPTp08zePBg3nvvPa677rpAhxPUEhMTSUhI4ODBg4EORZQjSXyl4LD9WdG9EF/rHrrsZRyYEIU4HA6GDx/OHXfcwR133BHocEKCzOys+CTxlUJUgjZGV5ivdQ9NMWUblxCFPf300+h0Ol5++eVAhxIypHRZxSeTW0qhTmvPBX+vrHuow0B9Yx90GPnDsZSDjh/pFvXq5YsVlQYdwmi6nPC7zz//nLlz57J+/fr8ySyieKoK18T0YNs3Z/hBr415JtSCa2/SlneIikFKlpXS/4bA7h88n/vVNpP11kmcde4sUPewtqFD/jUO8thadxx3PdaFYcOGER0tP1Wi7GzZsoVevXqxdOlSWrRoEehwgp41BzbNgRVvQfYJJzaLHb0Sid6gJT+XE1oPh84PQrVGgY5WXC1JfKW0dyVMuwtsuaV7fdUUlWb//JbJkyezevVqRowYwQMPPEBqamrZBirCzpkzZ2jXrh0vv/wyw4cPD3Q4Qe/UXpjSX6thassr+jqdQfu65UXocJ//4hNlT8b4SqlhZ0hqqu1I7StjJAx4SaF///4sWLCAjRs3kpCQQO/evencuTMzZ87EYrGUfCMhCnE6ndx5553cfvvtkvS8cGovvNsTck4Wn/RAW8LksMB3z8Hyt/wTnygf0uK7CuZseKc7nD/ieczPE2MU9HsOOo11P2e32/nmm2+YMmUKGzdu5O6772bMmDE0bty4bAMXFdZTTz3F+vXrWbRoEQaDDOEXx5YHr7bWkp6vvwWNUfCXadC0d/nEJsqXtPiuQlQCPPIj1L4ejNEuXBS96NUQqX0NfN1z0gMwGo0MHjyY77//njVr1mAwGOjcuTM9e/Zk9uzZ2GxeZlcRlmbPns0XX3zB559/LknPC1vmaWN7npJecfV2QStAsehffgxWlClp8ZUBVYUtCy/yn7tWc01kH+wuMzpFjylC6wfVG7Vkd8Pd2k7YvrBarWRmZjJ58mR27txJeno6Y8aMoUGDBuXwSUSo2rZtGz169GDx4sW0atUq0OEEPVWF/7aD0/vczxVVb/eQYyXdo17Lv84YBeMWQ83mfgxclAlJfGUkLy+PKlWqcGK/mfF3/ocbWnWjY+f2xCVp27noymA2+a5du/jwww/59NNPadOmDWPHjqV///5X/XSvqirZzuPkus7jVG3oMRGtTyBRX1M25AwBZ8+e5YYbbuCFF17grrvuCnQ4IeHQRpgyAOyFxvWsajbvZ9fmpugMmpqGFnsPnR5aD4Oh75VjoKJcSOIrI06nE6PRiNPppEuXLrz00kt06dKlXN7LbDbz5ZdfMmXKFH7//Xfuvfde7rvvPurUqePTfRyqjaPWXfxu3YhdtfxZhc0F6FAAoxJBvYhW1IpohlEJ8yKOQcrpdNK/f3+aNWvGG2+8EehwQsbaafDN/7knvv32RczN7c8TCRavSg9Wawx/W1tOQRbDZj/L+fNryMs7gMtlQVH0GAzxJCbcQGxsUxQvyyaGK/nulBG9Xo9Op8PhcHD06FFq1apVbu8VFRXFyJEjGTlyJNu3b2fKlCm0bNmSjh07MnbsWPr27VviguVsxwk25M7HpTpxUbjEmlP7p2pnr2U1+yxraR17K4mGmuX0iURhlguwcTZs/BxyT2tdc5EJkHoL3Jh+ucv82WefxWq18uqrrxZ/Q1GA5YK2PVhhvtbbteaUcWAlMJsPcur0EqzWI2htFmf+Obv9LBbLUZSTCgkJN1Clcjd0OqN/AwwR0uIrQzExMRw/fpzq1atz+vRpYmL8V5MsNzeXL774gsmTJ3PixAnGjBnDPffcQ82a7snqvOMY63MyPSS8oukw0Dr2Viobapdl2KKQnFOw8F+weS7odO5T7A2RgAqNuoO+4yKe/e9Y1q1bR7Vq1QISrzecDm2NnCk6eHZ/WP0xLHhWxWEp2JXva4svumYe47OsVKpUqbxCzZd9YTMnT36DqpZc5FdRDJiMVUlOHo1eL8UxCpPEV4YqV67M+vXradWqFdnZ2QGLY+PGjUyZMoXZs2fTs2dPHnjgAXr27IlOp8PiukjWhVk48X2GqB4jHeLuIkofXw5Ri0sLqXPPelHAXFGxqTn0nXSMfqODb7lL3nlYPwN+el/bzURn1NbBRcZB+3RIuxcSk/0b04ULF1izZg1ZWVls/9ZJ3b0TMCkF/y5fGuO7OfoTmpiGlHjPc9Hr+OxCDypVqkSLFi24/vrradGiBS1atCAlJaXMSsXl5Ozk2PE5qF4WwNfoMZmqUrfOGGn5FSKJrwzVrFmTzz77jAcffJCdO3cGOhwuXLjArFmzmDx5Mjk5OYwZM4be97bgtH4v6hVLL0Zd/zxWi51pm54jMkZ7JF84/WeWzV7PawvG51+noKO2KZVro7v5+6NUeBeOwZtdIO+Mb2vKTNEwdqG2pCYYOO0w/++w4TNtU1u72f0avUk7l9IVhk2B6MTyieXgwYNkZWWRlZXFqlWr2Lt3L61bt6Zjx46kte/EukduwpbjvqJLm9X5H/pGTSm23m5ErBZ/s34uDhw4wJYtW9i6dStbtmxhy5YtnDhxgtTU1AIJ8frrrycx0bcP7HTmsv/AGx5bevPmbSFj6moOHjxHbGwEvXo35YknehAfHwloLb/4+DYkVb/Ft29eBSdjfGUoIiKCQ4cOeexeDIT4+HjGjh3LAw88wC+//MKHH0+hiUVHVIx7f5PT4eSrySu484k+Rd5PxcUx206aRHVEr8gTZFmadR+Yzxe9pmyd9Q3OOndhUuKorm9JWuQzJBs6YcuDjDvg/34tm5nDV8Nuho8GwdGtWoWTolwq9rBnObzdBR5aDPE1ru69HQ4HW7duzU90WVlZWK1WOnbsSMeOHRkxYgStW7cmIuLy333DZlj1gXvxiXaRjxOtS+Jn60QW5I0oUG/3SnojNO0DOp2Ohg0b0rBhQwYPHpx//sKFC2zbti0/Ic6aNYtt27ZRpUqV/FbhpYTYsGHDIluH2dkb8LQB6NT/rebjj1fzyn9uJS2tASdOXORfzy8kffQMPvs8HZNJj6o6uHBhI9Wq9kanK0WZqSJcOA5rMmD/KrBka13wlerCjffANR21B5tgJomvDEVERJT7xJbSUBSF9u3bU6dVAjtyf/Q4tjf0kZ7MfvsHBtzXidiE4sYEFI7ZdpMcITVFy8rpfdr0epeHXqyi1pTtsc8n2dAJ0OrF/rYEmvXzc+BXcLng01FwZEvxSe9KThtkH9OWFYz/UWtBeevixYv53ZZZWVmsXbuW5ORkOnbsSL9+/XjxxRdJSUkpdjlO2r3w85Qrp4dclmoaQappRJGvNUZBp4dAX8xv0Pj4+PzEe4nL5WL//v35rcKZM2cyYcIETp065bF1GB8fx7nzq926OHNyrLzzzgpeenkAXbqkAJCcnMibb91Or57v8PXX2xgypOWfVytcvLidhITWRQfrpSNb4PuXYN9K7b8d1svnDm2EXYshKhG6jte+v4F+GCuKJL4yFKyJ75JzjqO4FM9jBI1a1aVFpxS+fGcZo//Rv8h7OLFzznFUEl8ZWjVZq/5fmFXNZpXlOW6KzqCx6XJLIsU4gBTjgMvX5cDytwOb+HZ8BwdWe056xbVYXQ44fwhWvAt9nir6/ld2W2ZlZbF79+78bsvx48fToUMHqlSp4lPMlerA7W/D3Ec9d8kWxRABya2h22M+vR2gtQ5TUlJISUnh9ttvzz+enZ1doHU4Y8YMtm/fTvfu1/LSy72JjCyYQTZuPITV6qBPn2YFjsfEmOjSJYWfs/bnJz5VtXH+/JqrTnxbM2H2Q2C34KkBCqr2EGbLhYXPw85FMGpGcG7nJImvDEVERHD8+HFuvPHGQIfikd1V/E/3qKdv5q/93mTg2K7F30f14beEKNGGzzxPZjniWI0DC42Ng0q8x+GNcPGk75WBysrytzzvVOJNi9VhhZ8/hJ5/01pQDoeDbdu2FUh0Foul2G7L0mo1VIv7m6f//IVeAmOUth/n6M+Lb+35KiEhgU6dOtGpU6f8Y06nk337l+J0roZC5RDPncujUqVoDAb3Mcpq1WL59ddjBY45nBevKr4dC/9Mel7+6NvN2oPQtLvg3rnB1/KTxHeVjmyFn96FXUug2/mfYR+cynIxZz90fghqNCv5Hv5S0rhc/Wtr0b5vKl+8uZS6jZNKfR/hPYe16F8mvqwp05u0cZdAJL5Te+DYdvfj3rZYAWxmB8+nf8ma4/9j7dq11K5dm44dO9KnTx/+9a9/0ahRo3KrItR+tLbH3qIXtK48l8v9QSQiVhvH6vwQdHmkbJNeUfR6PUnVq3LylB5VLZj4KlWK5ty5PBwOl1vyO3Uqh0qVCjazfJsNWtDFk9oYtKe/p8W15h0W+OMXWP4m9Hii1G9fLiTxldIfv2hdJGf/AIcNVCfoMIIKzlztKX7LXKjeGIa8A7WuC3TEEKWLR0FXYEZnYSOfvpmHu73K7eN6FHGFQpROljOUFbtF2+PN0+4eUUoV8tTTuFRHicnv4sULDBn4AJaEXURFRREVFUV0dHSJf/bluqImX/z6neeuWl9arE6LAef2VMa/MJ60tDSqVq1a4mvK0jUd4aHv4fR+yJqs/Xybs7UWXmKytv9e457+b7nodBF42kugVatkTCYDixfv5OabLw875OXZWLlyL48/XvDn9/TpbJ7/519o1qwZTZs2pVmzZqSkpGAylTzhZe0noHr4leFNa95uhp/eg66P+udhwVtBFEro2L4APh9TfLNfdWrnj2yBD/rByBnQuLv/YvSkpqkpv1s3euyev6T2NdXoMqg1mVNW0OBa97FKu9XOT99tpfrNqT5PyxbuImLBZVcB99ZMbUMaBiLZY88scU1ZTEwsr78zkcia2ZjNZvLy8jCbzflfV/53bm4up0+f9niuqD+bzWaMRqPHpNj03JPUst/hFpOvVVDqVb+OAQMC+4RY9Rq4LYiK4ERE1MTT9Ju4uEjGPdyFiS9+T2xsRIFZnTVqxHPbwILfx9jYuvTqdS27du1i+vTp7Nq1iz/++IN69eoVSIZNmzaladOmJCQkANoDTdYU97FbX1rzTrs26SX15rL5npQFSXw+2p9VctIrzJYH00fA2G8hOYCF82P0icTpq5HtPF7sdSOe7McPX6zzeM5gj+H7zKU88dDT3HzzzaSnp9OjR48yW6gbLs6dO8eyZctYsmQJOuUp4tT6btdEKAl0inyBJeZx6DAUu6YMVUe7Hg0xRpVPvKqqYrVaPSbFdW/V4uB37q/xpcUKnlsV4c5kqkJERE0slkNu5+6/vwOJiVG8+p+ll9fx9WrCf18fiMl0+futKEYaXjOA5qn1CrzearWyb98+du7cyc6dO1myZAlvv/02v/32G/Hx8TRr1ozUxEFE594PFBxP9aU1b83RWtHBlPhkAbsPXE6Y2ARyz7ifK66v+5LEOvDUlsCucTlpP8C23EU4fShXdokOA9dF9ybJlMKZM2f47LPPyMjI4NSpU9x9992MHj2ahg0blkPUoc9ut7N27VoWL17M4sWL2bFjR/4YVj3zMDa9XxNbrue/GL/aZrLeOomzzp0F1pTVNnQAtKooN4yEQa/78xNdtuy/sPgVrZfjSr5WQWnaF9I/L6cgQ5hWtWUuqlq6/TgNhkQa1P+r12OkLpeLw4cPs3PnTjbM1HP+u84ozoKJ71fbTJabn2BcQvEP0ZdUqqv97gsW0uLzwa7vC65bucSbvm6AvLNw4GdtPCFQqhnqU8PYmGP23T7X6kwyNqS6UUtsVapU4eGHH+bhhx9m69atZGRkkJaWRrNmzUhPT2fIkCHExvqwMKuCUVWVPXv2sGTJEhYvXszy5ctJSUmhd+/evPzyy3To0IHISK26hjUHNr5b9L1KWlOm0xe9ubE/NOoByya573TgS4vVFAPX3ernwENETExjDIY47PZzFJ7dWRJFMVK1Sm+fJgbpdDrq1q1L3bp1iTkA330PzkIPNb625r2ZMetP0uLzwft9tUHvK/myfxcKNO0N6V+UX4zeUFUX2/KWcNK+36vkp8NANWN9rovui05xH2i/xGaz8e2335KRkcFPP/3EoEGDSE9Pp1OnTmGxr9/Zs2f54Ycf8pOdw+GgT58+9O7dm169ehVbSPr7ifDTB+7JoySGSGjUDUZ/dnWxX63/ttNqjXpSUosVtMT33B7Kras21NkdFzh48AOcTjPeJj9FMVIpMY2qVXuV+n3XzYSvJ7gXS/e1NV+lAUzYWOowypwkPi/lnYeJjd23MvG1mrvOAC8eAUPZVQ8qFVVVOWzdxj7rOpyqHSfuC8n0GNErRhpEtKVuxPU+Ja/jx48zY8YMMjIysNlsjB49mlGjRvm8Z2BRXC74fTWcO6Stw4qMg6Rm/p09a7PZWLNmDYsXL2bJkiXs3LmTzp075ye7Zs2a+dC9BDNGwe4fvU9+hgio2hDGLQn8IuF1M2H+BN8TN2hdtTeODq5JJcHIbs/m8JEMHI6cEro9dSiKjiqVe1CpUsereug8vAkm9/f8/9XbmqaKDpoPgL98UuowypwkPi+d2gtvdwdbof23fO3rNkTC01shNkh2kVFVlbOOQ/xu3USu8xxO7OgxEqNPpF5EK6oY6l7VD46qqqxbt46MjAxmz55N27ZtSU9PZ+DAgfldfb7IOwfrZmhTpK25gKqNveoNWvKoVEerqHH9QDD6fvsSP8tvv/2W36JbuXIljRs3pnfv3vTp04e0tLSrWlTtcsK8v2pbEjksxU/2MMVoE6VGf+Zbqa/yYrfAOz20n5MSd5YoJLoK/HXV1dfrDAcul4OcnF85e+6nP7s+QVWdgIKi6AGV+LgWJFZKI8J09b9kVFVrzZ/e5/m8V635aLgvE+q1u+pwyowkPi8d36l1dVoLFUDwtcVnjIK/rYPEMNzWzmw2k5mZSUZGBhs2bGDYsGGkp6fTtm1br5LrnuUw/S9aQihuVq0pRksGY77W1lFejdOnTxfovgTyW3Q9e/Ysl/VmB9fDyne1kk86459r/FStKLLLCXVvgG7jtbE1XdE9z36Xcwre6QkXT3hel1iYotP+P439DmpKBTyfWazHsFgO43Je2oE9jpiYxn+u/Ss762bA1095rszjjarXwN/WB1fhakl8Xso+Cq+28byexZe+bp0e/vWH9ss5nB08eJDp06fzySefEBkZSXp6On/5y19ISvJcMWbHQph1r/fLSBQFTLHaomRfqufYbDZ+/vnn/O7L3bt306VLl/xk16RJE7+NV+ae0YpP557VEl50JWjYBSrX9cvbl0reea1M1ZHNWvLztLAdRWsFxCXBvV9q4z8ieNny4D+ttAebYhcBe2CMgjve13pggokkPi+5XPDytdrTbGHe9nUDVLkGJmzwU9AhQFVVfvrpJzIyMsjMzKRLly6kp6dzyy23YDRqpdGO74B3e/m2dhIABWKqaC3sovZ8U1WVXbt25S8z+Omnn2jatCl9+vShT58+3HjjjV5VtxAFHd2mbUK7NVNrqSqK1m3mtGnJu+v40Ni+RmhO/Abv9bo8vOANYzR0vB9uer48IysdSXw+WPEOLPm351/A3s5cG/Bvbc2VcHfx4kW+/PJLMjIy+O233xgxYgTp6elsfu06fl3g+151oD1x9npK6xq85NSpUyxdujS/+1Kv19O3b1969+5Njx49fK7yL4pmzdEmIFkvaq28hNpay1WEnuM74cNbtS7P4h5CFZ028arbX7XC48H4cCOJzwd55+Cla73fb6wwY7Q2ZTvQM/BCwd69e/nkk0/4/JNvGJj3C3rVfdyiqPWThxwr6R71Wv51sdVVOrz3I0uWat2X+/bto2vXrvndl+VZAFmIisScDes+1cagrX8mwEuFC0zRWs9Y6s1aIe/klgENtViS+Hy06EVt/zRfp20bo6H3U9D1kfKJq6Ja+l8XP7zmwmUrOHHIl/WTNvUiv9V5lraD4unTpw/t27fP70YVQvjO5YK9K7Sx3LyzWm9WfE2tCEEotOilcouP+v4Dzv6uTbbwdszJGA2th0GXh8s1tArpQJYOl8196qIvtQJNulgeH/UmvZ4sjwiFCD86nVZ0P9CF90sriCZDhwZFgeEfwY3p2po8fTHzHnRGF4YIbSB/0OvB2dcd7MznizjuS+V/VSH3VJmGJYQIYZL4SkGng/4vwRNroMP92lqkiDiIiIfIeO3PmMw4r/2RJzdA779L0istQxFLkq6sFeiNcF8+IoS4TLo6r0LletB/IvR7Vivtk3dOS3DRlSEn6nd69x3Jv2scAmTLntKqVPfP+qiFRqJ92avOGAUJ7lsLCiHClCS+MmCIgPo3Fj7ajNq1a/PDDz/Qp0+fQIRVIbS/G3Z85141wpfK/6or+BbQCiECRxJfORo1ahTTp0+XxHcVGnTQZol5KpfULvJxonVJ/GydyIK8EQXWT16iKNC4Z/DURhVCBJ4sZyhHp06dolGjRhw6dIi4uLhAhxOyfv4YvntOxW72faDUGAX3fQX125dDYEKIkCSTW8pRtWrV6NKlC/PmzQt0KCEtdchFzhg34tJ52AW4GMZo6DBGkp4QoiBJfOVs5MiRfPrpp4EOI2SdOHGCHj274eyZQUoHo9cblRqjoe0IuOmf5RufECL0SFdnObNYLNSuXZstW7aQnJwc6HBCyp49e+jXrx+jRo3iueeew+VUWPY6ZH2gVf23Ftob8VLV/+hK0PtpaHtXQMIWQgQ5SXx+MGbMGBo2bMjf//73QIcSMtatW8ett97KCy+8wP3331/gnNOuVc756X2tALLDrK3Tq9lcq47ToIOsmxRCFE0Snx+sWrWKBx54gO3bt0sxZC8sWrSIkSNH8r///Y9bb7010OEIISoYGePzg44dO2I2m9m0aVOgQwl606ZNY/To0cyfP1+SnhCiXEji8wNFURg5ciTTp08PdChBS1VVXnnlFf75z3/y448/0qFDh5JfJIQQpSBdnX6yZ88eOnXqxOHDh2VLnEKcTiePPfYYK1asYNGiRdSqJfXFhBDlR1p8ftKoUSMaNmzI4sWLAx1KULFYLAwfPpzt27ezcuVKSXpCiHInic+PZE1fQefPn6dfv34oisKiRYtITEwMdEhCiDAgXZ1+dPbsWRo0aMDBgwdJSEgIdDgBdeTIEfr160ePHj2YNGkSOp08gwkh/EN+2/hR5cqV6dmzJ19++WWgQwmonTt30rFjR0aOHMmbb74pSU8I4VfyG8fPLu3YEK6ysrLo1q0bL774IhMmTJB1jUIIv5OuTj+z2WzUqlWL9evXU79+/UCH41fz58/n/vvv59NPP6Vv376BDkcIEaakxednJpOJYcOGMWPGjECH4ldTpkzhwQcf5LvvvpOkJ4QIKGnxBcCaNWu4++672bVrV4Xv6lNVleeff56ZM2eyaNEiUlJSAh2SECLMyQ7sAdC+fXtUVeWXX36hffvQ2izOboELx8F6UdsJIS4JImI9X+twOHjwwQfZtGkTWVlZJCUl+TdYIYTwQBJfAFwqYfbpp5+GTOI7tQdWTYYNn4MCKHpQXeByQLO+0OURqNPm8q4IeXl5DB8+HKvVyvLly4mNLSI7CiGEn0lXZ4AcOHCAG264gSNHjmAymQIdTpEsF2BmOuz/WUtyLof7NYoODJFQuR7cMxucUWfo378/jRo14uOPPw7qzyeECD8yuSVAGjRoQLNmzVi4cGGgQylS3jl4uzvszwKHxXPSA63lZ8+Dk7vhjY5O+rb/C127dmXatGmS9IQQQUdafAH08ccfs3DhQubOnRvoUNw4bPB+Hzi+Q9v41VsunBhiLDyzKYbYauUXnxBClJa0+AJoyJAhLF26lLNnzwY6FDdb52njep6S3g7bLKZdbMuk87G8l12TOTk3cdixCgAdehRbDMvf9G+8QgjhLUl8AZSYmEi/fv2YPXt2oENxs/wtsOW5H19neYNl5sdIi/g/xiWcYGz8QVpFPMQe+/z8a5x2WDtdmwEqhBDBRhJfgAXjjg1HtsDZP9yPW9VsVlmeo1fUezQ2DcakxKBXjKQYB9A96jW367fNd7+HEEIEmiS+AOvbty979+5l7969gQ4l329LtTG+wo44VuPAQmPjoBLvYcuBrZL4hBBBSNbxBZjRaGT4bfeT8fAh4o6mkHcOXC6IiIGUrtDlYajdwr8xXTwJqtP9uFk9Q7RSFZ3i3V+b3NNlHJgQQpQBSXwBlH0Uvnocope9gMVu48rVAvY82DIPfv0OKtWB216FlC7+iUspoh8gSqlCnnoal+rwKvkVdR8hhAgkSXwBcmIXTL4FzNmgOnUYiHS7Jn993G/wyXC47TVoN6LsY3G5XOzdu5cNGzawYcMGjn7XmFrqaPRKwTV4tQ1pGIhkjz2TJqYhJd5XljMIIYKRJL4AOH9ES3p5PqxisJth/pMQXQlSby79e7tcLvbs2ZOf5DZs2MCmTZtITEykTZs2tGnThrTHm7HxH0Yc1oKvjVAS6BT5AkvM49BhoL6xDzqM/OFYykHHj3SLevXytbHQsuTcKIQQficL2APgo4GwfxW4PIyj7bDNYp31Dc46d2FS4qiub0la5DMkGzoBYIyGZ3dBRFzJ7+Nyudi9e7dbkqtcuXJ+kmvTpg2tW7emWrWCzbO3u2mzOz351TaT9dZJnHXuxKTEkaRvQ1rkM9Q2dMi/JioBnt0DeqOX3xQhhPATSXx+du4g/Le9VgKssHWWN1hrfYU+UZOpb+yLHhMHHIs45FiZv1zAFA03vwhp9xR8rdPpdEtymzdvpkqVKm5JrmrVqiXGuTUT5jwMtlzfP6M+ArqMg37P+v5aIYQob5L4/Ozb5yBrCjgLLRewqtm8n12bm6IzaGoaWuw9KtVVGTBrJxs3Fkxy1apVc0tyVapUKVWcLid8NAgO/oJbl2dxdHpIqA2PrtRafUIIEWwk8fnZCymQe8b9+H77Iubm9ueJBEuJMybtai7LE4fQqH18fpJr1aoVlStXLtNYrTkwZQCc3OVdFRadEWKrwkPfazNRhRAiGMnkFj8zZxdx3Ic1crHxUXzxyUIadSvb2AqLiIUHF8Lcx2BbJqB47qLVGbWWXt228JdPIKZ0jUwhhPALSXx+pKqeJ7SAb2vkFEXnU/fj1TBGwvDJcMsLsPYTrZvWchH0Bu2z6AzaEouOY6HqNf6JSQghroYkPj9SFC2R2M3u53xZI6cCUYnlEmKR4qpDrwnQ80mtHJnlIphitNmlOlmoLoQIIfIry8/qtPZ8/Mo1cntsmdjVPJyqnf32hSw3TyhwrdMGNZr5IVgPFEVLdgm1tMkrkvSEEKFGWnx+1vVROLzZ8zKBdpGPE61L4mfrRBbkjSiwRu4SRQ8tb4fIeP/FLIQQFYnM6vQzlwteago5p0r3emMUjFsCNVPLNi4hhAgX0lHlZzod3PKSlsB8ZYiCRt0l6QkhxNWQxBcArYdq2w35kvwMkZDUBO76X/nFJYQQ4UC6OgNo1WRY+C+tpqbL5vkZRNFpSe+ajjByWulaikIIIS6TxBdg2Udh4oil6HZ0ICIiGtDW+ymKNnvz2pu11mFRs0GFEEL4RhJfgNntdurWrcuypcuJON+EnFPgtGvr9Oq0gZiyrUImhBBhT5YzBNiiRYu45ppraJbaJNChCCFEWJDJLQE2depU0tPTAx2GEEKEDenqDKCTJ0/SuHFjDh48SHy8rEgXQgh/kBZfAM2YMYPbbrtNkp4QQviRJL4AUVWVqVOncs8995R8sRBCiDIjiS9A1q9fj9lspkuXLoEORQghwookvgDJyMhg9OjRKIoS6FCEECKsyOSWADCbzSQnJ7Np0ybq1q0b6HCEECKsSIsvADIzM2nTpo0kPSGECABJfAGQkZEhk1qEECJApKvTzw4ePEirVq04cuQIkZGRgQ5HCCHCjrT4/GzatGkMGzZMkp4QQgSItPj8yOVykZKSwuzZs2nbtm2gwxFCiLAkLT4/WrlyJTExMbRp0ybQoQghRNiSxOdHlyq1yNo9IYQIHOnq9JMLFy5Qt25d9uzZQ7Vq1QIdjhBChC1p8fnJ7Nmz6dGjhyQ9IYQIMEl8fiL77gkhRHCQrs4y5nSasViP4nKaURQ9en0Mf/yRQ/fuPTl06BAGg2x6L4QQgSS/hcuIxXKMc+eyyMndgYIeFVAUQFWx2a28/vpowALEBjROIYQId9Liu0oul51jx+eQl7cPVXUAnr+dqqpHp1OoVvUmEhPb+TdIIYQQ+STxXQWXy86hw1Ox2U78mfRKpihGKlfqQpUqXcs5OiGEEJ7I5JarcOz4lz4lPQBVtXP23EouXNxWjpEJIYQoiozxlZLVeoK8vD0ek968eVvImLqagwfPERsbQa/eTXniiR7Ex2v1OVXVzqlTi4iLTUVR5NlDCCH8SX7rltK586tRVafb8an/W81/X/uBJyf0Yv2GCXwx+x6OHskmffQMbLbL17tcVvLMB/wZshBCCCTxlYrLZeXixa0UnsiSk2PlnXdW8I9n+9KlSwpGo57k5ETefOt2jh7N5uuvL3dvqqqNc2dX+TlyIYQQkvhKwWo9jqLo3Y5v3HgIq9VBnz7NChyPiTHRpUsKP2ftL3DcbDlUrnEKIYRwJ4mvFJxOi8fj587lUalSNAaD+7e1WrVYzp3LK3BMVe3IpFohhPAvSXyl4Km1B1CpUjTnzuXhcLjczp06lUOlStGF7yQ7NQghhJ9J4isFgyHWY0utVatkTCYDixfvLHA8L8/GypV7SUtrUOC4Xi+7sAshhL9J4isFkykJvc49acXFRTLu4S5MfPF7Vq7ci93u5PDh8zw6fi41asRz28DrrrhaT3xcS7/FLIQQQiOVW0rp3LnVnD6zFFW1u52bM2cT0z5Ze3kdX68mPPG3HiQkROVfoygG6tcbj9GY6MeohRBCSOIrJafTwv4Dr3lMfCVTiIqqT51k2aZICCH8Tbo6S0mvjyQpaRCKYvT5tTpdJDWSBpdDVEIIIUoiie8qxMc1p1rVviiKt5XfdOh0UdRJvgejMaFcYxNCCOGZdHWWgdzcPZw89S0Ox8UitibSoyha92ZS9dsk6QkhRABJ4isjqqpisRzm7LkszOYDqKqNSy28+PgWJCa2x2iID3SYQggR9iTxCSGECCsyxieEECKsSOITQggRViTxCSGECCuS+IQQQoQVSXxCCCHCiiQ+IYQQYUUSnxBCiLAiiU8IIURYkcQnhBAirEjiE0IIEVYk8QkhhAgrkviEEEKEFUl8QgghwookPiGEEGFFEp8QQoiwIolPCCFEWJHEJ4QQIqxI4hNCCBFWJPEJIYQIK5L4hBBChBVJfEIIIcKKJD4hhBBh5f8BGSQyEsMYZUQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x19c78103460>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#displaying one sample\n",
        "plt.clf()\n",
        "visualize(training_set[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf63B6JvyGS4"
      },
      "outputs": [],
      "source": [
        "#vocabulary size\n",
        "max_vocab = 500\n",
        "# maximum length of the tokenized vector\n",
        "max_len = 100 \n",
        "\n",
        "# build vocabulary from training set only for nodes characters\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "\n",
        "#training tokenizer\n",
        "tokenizer = Tokenizer(num_words = max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcIrQLZ5yMy0",
        "outputId": "0cdb6404-f184-489f-f431-581164149845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "Shape is (160,)\n",
            "edges\n",
            "Shape is (108, 2)\n",
            "node2grah\n",
            "Shape is (160,)\n",
            "label [0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)  \n",
        "        print(\"Shape is \"+str(np.shape(v)))\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GqNIGHTyO79",
        "outputId": "bc969733-1f62-4622-c453-165678461aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 80)           40000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 40)           34640       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 40)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            41          ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 74,681\n",
            "Trainable params: 74,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
        "\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 40\n",
        "gnn_layer = GNN(params)  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBbmmo-PyRel"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5c2VwP-ycpz",
        "outputId": "0e1ecef3-6faf-4858-a30a-274b14da4d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1265/1265 [==============================] - 20s 14ms/step - loss: 0.6196 - auc: 0.7159 - val_loss: 0.5928 - val_auc: 0.7495\n",
            "Epoch 2/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.5856 - auc: 0.7565 - val_loss: 0.5774 - val_auc: 0.7739\n",
            "Epoch 3/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.5685 - auc: 0.7764 - val_loss: 0.5663 - val_auc: 0.7829\n",
            "Epoch 4/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.5503 - auc: 0.7945 - val_loss: 0.5488 - val_auc: 0.7961\n",
            "Epoch 5/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.5370 - auc: 0.8066 - val_loss: 0.5358 - val_auc: 0.8127\n",
            "Epoch 6/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.5239 - auc: 0.8180 - val_loss: 0.5197 - val_auc: 0.8232\n",
            "Epoch 7/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.5109 - auc: 0.8287 - val_loss: 0.5065 - val_auc: 0.8307\n",
            "Epoch 8/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.5010 - auc: 0.8362 - val_loss: 0.4928 - val_auc: 0.8426\n",
            "Epoch 9/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4896 - auc: 0.8445 - val_loss: 0.4914 - val_auc: 0.8426\n",
            "Epoch 10/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4781 - auc: 0.8522 - val_loss: 0.4759 - val_auc: 0.8547\n",
            "Epoch 11/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4666 - auc: 0.8605 - val_loss: 0.4616 - val_auc: 0.8646\n",
            "Epoch 12/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4567 - auc: 0.8670 - val_loss: 0.4545 - val_auc: 0.8691\n",
            "Epoch 13/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4466 - auc: 0.8738 - val_loss: 0.4423 - val_auc: 0.8769\n",
            "Epoch 14/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4353 - auc: 0.8807 - val_loss: 0.4236 - val_auc: 0.8875\n",
            "Epoch 15/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4264 - auc: 0.8862 - val_loss: 0.4247 - val_auc: 0.8899\n",
            "Epoch 16/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.4189 - auc: 0.8902 - val_loss: 0.4212 - val_auc: 0.8920\n",
            "Epoch 17/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4106 - auc: 0.8951 - val_loss: 0.4003 - val_auc: 0.9016\n",
            "Epoch 18/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4016 - auc: 0.8996 - val_loss: 0.3878 - val_auc: 0.9079\n",
            "Epoch 19/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3962 - auc: 0.9025 - val_loss: 0.4007 - val_auc: 0.9022\n",
            "Epoch 20/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3851 - auc: 0.9083 - val_loss: 0.3832 - val_auc: 0.9097\n",
            "Epoch 21/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.3785 - auc: 0.9118 - val_loss: 0.3824 - val_auc: 0.9140\n",
            "Epoch 22/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.3704 - auc: 0.9156 - val_loss: 0.3876 - val_auc: 0.9093\n",
            "Epoch 23/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.3645 - auc: 0.9179 - val_loss: 0.3811 - val_auc: 0.9201\n",
            "Epoch 24/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3609 - auc: 0.9198 - val_loss: 0.3686 - val_auc: 0.9167\n",
            "Epoch 25/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3545 - auc: 0.9227 - val_loss: 0.3449 - val_auc: 0.9273\n",
            "Epoch 26/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3490 - auc: 0.9250 - val_loss: 0.3660 - val_auc: 0.9205\n",
            "Epoch 27/30\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.3449 - auc: 0.9269 - val_loss: 0.3640 - val_auc: 0.9219\n",
            "Epoch 28/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3420 - auc: 0.9282 - val_loss: 0.3344 - val_auc: 0.9333\n",
            "Epoch 29/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3330 - auc: 0.9320 - val_loss: 0.3629 - val_auc: 0.9269\n",
            "Epoch 30/30\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3282 - auc: 0.9338 - val_loss: 0.3421 - val_auc: 0.9353\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "hist = model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=30,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=32, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-D5CvXMyeAM",
        "outputId": "54983a76-f777-4b7c-e2f6-7407b30b2856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 3s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iewvqJI9yf99"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({'label':y_pred})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('Trial_2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D6KVs3g-VJg"
      },
      "source": [
        "On Kaggle It Got 0.81 Thats not very good so lets try the others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbxr60pV-VJg"
      },
      "source": [
        "## Trial 3 Using Upsampling to fix the Data Imbalance And Changing GGNN Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzHH8oXOynto",
        "outputId": "7da1461b-af8c-433a-a6f9-d50e8ed5675f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 80)           40000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 32)           81152       ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 32)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          4224        ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 64)           8256        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            65          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 133,697\n",
            "Trainable params: 133,697\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model2 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4QlEYYj-VJh"
      },
      "outputs": [],
      "source": [
        "model2.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqwfhTFi-VJh",
        "outputId": "b754cf20-04f1-46d7-bbee-d27bf3d631f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "633/633 [==============================] - 59s 86ms/step - loss: 0.6332 - auc: 0.6908 - val_loss: 0.5823 - val_auc: 0.7616\n",
            "Epoch 2/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.5754 - auc: 0.7648 - val_loss: 0.5514 - val_auc: 0.7910\n",
            "Epoch 3/50\n",
            "633/633 [==============================] - 54s 85ms/step - loss: 0.5500 - auc: 0.7916 - val_loss: 0.5259 - val_auc: 0.8162\n",
            "Epoch 4/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.5230 - auc: 0.8183 - val_loss: 0.5071 - val_auc: 0.8340\n",
            "Epoch 5/50\n",
            "633/633 [==============================] - 53s 83ms/step - loss: 0.5042 - auc: 0.8334 - val_loss: 0.4946 - val_auc: 0.8423\n",
            "Epoch 6/50\n",
            "633/633 [==============================] - 52s 83ms/step - loss: 0.4811 - auc: 0.8506 - val_loss: 0.4588 - val_auc: 0.8707\n",
            "Epoch 7/50\n",
            "633/633 [==============================] - 53s 83ms/step - loss: 0.4519 - auc: 0.8698 - val_loss: 0.4183 - val_auc: 0.8900\n",
            "Epoch 8/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.4200 - auc: 0.8888 - val_loss: 0.3982 - val_auc: 0.9006\n",
            "Epoch 9/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.3957 - auc: 0.9019 - val_loss: 0.3804 - val_auc: 0.9147\n",
            "Epoch 10/50\n",
            "633/633 [==============================] - 54s 86ms/step - loss: 0.3726 - auc: 0.9131 - val_loss: 0.3573 - val_auc: 0.9250\n",
            "Epoch 11/50\n",
            "633/633 [==============================] - 54s 86ms/step - loss: 0.3509 - auc: 0.9227 - val_loss: 0.3261 - val_auc: 0.9326\n",
            "Epoch 12/50\n",
            "633/633 [==============================] - 55s 86ms/step - loss: 0.3321 - auc: 0.9305 - val_loss: 0.3136 - val_auc: 0.9380\n",
            "Epoch 13/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.3122 - auc: 0.9382 - val_loss: 0.2937 - val_auc: 0.9460\n",
            "Epoch 14/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2961 - auc: 0.9439 - val_loss: 0.2836 - val_auc: 0.9508\n",
            "Epoch 15/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2792 - auc: 0.9492 - val_loss: 0.2547 - val_auc: 0.9580\n",
            "Epoch 16/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2604 - auc: 0.9552 - val_loss: 0.2449 - val_auc: 0.9586\n",
            "Epoch 17/50\n",
            "633/633 [==============================] - 54s 85ms/step - loss: 0.2532 - auc: 0.9572 - val_loss: 0.2305 - val_auc: 0.9620\n",
            "Epoch 18/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2391 - auc: 0.9614 - val_loss: 0.2295 - val_auc: 0.9644\n",
            "Epoch 19/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2247 - auc: 0.9651 - val_loss: 0.2131 - val_auc: 0.9667\n",
            "Epoch 20/50\n",
            "633/633 [==============================] - 53s 83ms/step - loss: 0.2162 - auc: 0.9669 - val_loss: 0.2133 - val_auc: 0.9673\n",
            "Epoch 21/50\n",
            "633/633 [==============================] - 53s 84ms/step - loss: 0.2055 - auc: 0.9698 - val_loss: 0.2034 - val_auc: 0.9697\n",
            "Epoch 22/50\n",
            "633/633 [==============================] - 53s 83ms/step - loss: 0.2012 - auc: 0.9709 - val_loss: 0.1989 - val_auc: 0.9713\n",
            "Epoch 23/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1902 - auc: 0.9737 - val_loss: 0.1927 - val_auc: 0.9737\n",
            "Epoch 24/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1805 - auc: 0.9755 - val_loss: 0.1778 - val_auc: 0.9748\n",
            "Epoch 25/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1770 - auc: 0.9763 - val_loss: 0.1965 - val_auc: 0.9749\n",
            "Epoch 26/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1677 - auc: 0.9782 - val_loss: 0.1674 - val_auc: 0.9788\n",
            "Epoch 27/50\n",
            "633/633 [==============================] - 52s 81ms/step - loss: 0.1575 - auc: 0.9801 - val_loss: 0.1711 - val_auc: 0.9783\n",
            "Epoch 28/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1541 - auc: 0.9814 - val_loss: 0.1727 - val_auc: 0.9754\n",
            "Epoch 29/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1546 - auc: 0.9813 - val_loss: 0.1497 - val_auc: 0.9800\n",
            "Epoch 30/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1481 - auc: 0.9826 - val_loss: 0.1451 - val_auc: 0.9806\n",
            "Epoch 31/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1391 - auc: 0.9841 - val_loss: 0.1378 - val_auc: 0.9827\n",
            "Epoch 32/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1364 - auc: 0.9846 - val_loss: 0.1486 - val_auc: 0.9807\n",
            "Epoch 33/50\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1357 - auc: 0.9843 - val_loss: 0.1711 - val_auc: 0.9819\n",
            "Epoch 34/50\n",
            "632/633 [============================>.] - ETA: 0s - loss: 0.1259 - auc: 0.9867Restoring model weights from the end of the best epoch: 31.\n",
            "633/633 [==============================] - 52s 82ms/step - loss: 0.1258 - auc: 0.9867 - val_loss: 0.1754 - val_auc: 0.9819\n",
            "Epoch 34: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1,restore_best_weights=True)\n",
        "\n",
        "hist = model2.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Lvou8B5-VJh",
        "outputId": "883b7ec7-4d38-44f6-9dc1-77057f849ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 5s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "#make a prediction by using the model\n",
        "y_pred_2 = model2.predict(\n",
        "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
        ")\n",
        "y_pred_2 = np.reshape(y_pred_2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK52rhxL-VJh"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({'label':y_pred_2})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('trial_3_GGNN.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVGzDFq9-VJh"
      },
      "source": [
        "On Kaggle It Got 0.862 Thats actually very good but still will try the other HP first. So lets try RandomOverSample and see if it does better on same model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xglDXdST-VJh"
      },
      "source": [
        "## Trial 4 Using RandomOverSample to fix the Data Imbalance And Changing GGNN Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "10c59625271242e88060622c1b0bdc57"
          ]
        },
        "id": "Rb_UZE6h-VJi",
        "outputId": "34a13317-f78e-4f48-bd04-f01ecafef9f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10c59625271242e88060622c1b0bdc57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_set4 = read_sdf('train.sdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaYxNWsW-VJi",
        "outputId": "9e363f58-5cd1-437c-93fe-676a641a32ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_16828/1118175248.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  unique, counts = np.unique(np.array(training_set4)[:,2], return_counts=True)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "unique, counts = np.unique(np.array(training_set4)[:,2], return_counts=True)\n",
        "\n",
        "sns.barplot(x=unique, y=counts)\n",
        "plt.xlabel('target')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Counts of target')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCZZoVHi-VJi",
        "outputId": "d1376eb4-f8cd-44f0-da87-c243c08135b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeKaiTo\\AppData\\Local\\Temp/ipykernel_16828/1998894208.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data2 = pd.DataFrame(np.array(training_set4)[:,:], columns = ['0', '1', 'target'])\n"
          ]
        }
      ],
      "source": [
        "#convert the data from List to DataFrame to make upsampling\n",
        "data2 = pd.DataFrame(np.array(training_set4)[:,:], columns = ['0', '1', 'target'])\n",
        "data2['target'] = data2['target'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKX4zxHe-VJi"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=44)\n",
        "resampling = data2.copy()\n",
        "X_resampled, y_resampled = ros.fit_resample(resampling.drop('target', axis=1), resampling['target'])\n",
        "data_upsampled = pd.concat([X_resampled, y_resampled], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "004ECaCa-VJi",
        "outputId": "0634a45d-1552-4345-f94f-26ebb6b0e3bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    23806\n",
              "1    23806\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_upsampled['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epvLNAgT-VJi"
      },
      "outputs": [],
      "source": [
        "#converting the upsampled DataFrame into list\n",
        "training_set4 = data_upsampled.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAU5VUmi-VJi"
      },
      "outputs": [],
      "source": [
        "training_set4, validation_set4 = train_test_split(training_set4, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7hFrZMR-VJi"
      },
      "outputs": [],
      "source": [
        "#vocabulary size\n",
        "max_vocab = 500\n",
        "# maximum length of the tokenized vector\n",
        "max_len = 100 \n",
        "\n",
        "# build vocabulary from training set only for nodes characters\n",
        "all_nodes3 = [s[0] for s in training_set4]\n",
        "\n",
        "#training tokenizer\n",
        "tokenizer3 = Tokenizer(num_words = max_vocab)\n",
        "tokenizer3.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPDUqgxk-VJj",
        "outputId": "c514257f-0e7f-4e61-ba7e-89b70c66f4d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 80)           40000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           81152       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          4224        ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 133,697\n",
            "Trainable params: 133,697\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model3 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz4o9dhP-VJj"
      },
      "outputs": [],
      "source": [
        "model3.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKC6aDAb-VJj",
        "outputId": "8f1a0cba-f78f-4251-ce77-1a8a9c0ca423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 58s 90ms/step - loss: 0.6276 - auc: 0.6984 - val_loss: 0.5900 - val_auc: 0.7526 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 51s 86ms/step - loss: 0.5695 - auc: 0.7691 - val_loss: 0.5477 - val_auc: 0.7947 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 51s 85ms/step - loss: 0.5259 - auc: 0.8153 - val_loss: 0.5134 - val_auc: 0.8351 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 52s 87ms/step - loss: 0.4798 - auc: 0.8512 - val_loss: 0.4668 - val_auc: 0.8625 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 53s 89ms/step - loss: 0.4496 - auc: 0.8713 - val_loss: 0.4358 - val_auc: 0.8819 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 54s 90ms/step - loss: 0.4146 - auc: 0.8915 - val_loss: 0.4087 - val_auc: 0.9029 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 55s 93ms/step - loss: 0.3848 - auc: 0.9069 - val_loss: 0.3743 - val_auc: 0.9133 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 53s 88ms/step - loss: 0.3594 - auc: 0.9184 - val_loss: 0.3562 - val_auc: 0.9201 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 53s 89ms/step - loss: 0.3454 - auc: 0.9251 - val_loss: 0.3226 - val_auc: 0.9357 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 53s 90ms/step - loss: 0.3216 - auc: 0.9346 - val_loss: 0.3210 - val_auc: 0.9376 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 49s 82ms/step - loss: 0.3046 - auc: 0.9409 - val_loss: 0.2906 - val_auc: 0.9455 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.2952 - auc: 0.9440 - val_loss: 0.2855 - val_auc: 0.9491 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 50s 83ms/step - loss: 0.2829 - auc: 0.9482 - val_loss: 0.2680 - val_auc: 0.9531 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.2675 - auc: 0.9531 - val_loss: 0.2563 - val_auc: 0.9574 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 49s 83ms/step - loss: 0.2605 - auc: 0.9550 - val_loss: 0.2436 - val_auc: 0.9595 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.2466 - auc: 0.9590 - val_loss: 0.2553 - val_auc: 0.9587 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.2362 - auc: 0.9622 - val_loss: 0.2280 - val_auc: 0.9661 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 46s 77ms/step - loss: 0.2289 - auc: 0.9641 - val_loss: 0.2079 - val_auc: 0.9695 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 46s 77ms/step - loss: 0.2190 - auc: 0.9673 - val_loss: 0.2076 - val_auc: 0.9693 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 46s 77ms/step - loss: 0.2125 - auc: 0.9684 - val_loss: 0.2217 - val_auc: 0.9707 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "596/596 [==============================] - 46s 77ms/step - loss: 0.2047 - auc: 0.9702 - val_loss: 0.1952 - val_auc: 0.9723 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "596/596 [==============================] - 47s 78ms/step - loss: 0.1957 - auc: 0.9726 - val_loss: 0.2126 - val_auc: 0.9720 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 47s 79ms/step - loss: 0.1887 - auc: 0.9746 - val_loss: 0.1776 - val_auc: 0.9754 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 47s 79ms/step - loss: 0.1787 - auc: 0.9766 - val_loss: 0.2131 - val_auc: 0.9734 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.1737 - auc: 0.9775 - val_loss: 0.1738 - val_auc: 0.9766 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "596/596 [==============================] - 47s 78ms/step - loss: 0.1714 - auc: 0.9778 - val_loss: 0.1799 - val_auc: 0.9774 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.1662 - auc: 0.9794 - val_loss: 0.1630 - val_auc: 0.9788 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.1567 - auc: 0.9812 - val_loss: 0.2289 - val_auc: 0.9747 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 48s 81ms/step - loss: 0.1534 - auc: 0.9816 - val_loss: 0.1568 - val_auc: 0.9795 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.1520 - auc: 0.9822 - val_loss: 0.1551 - val_auc: 0.9810 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 48s 81ms/step - loss: 0.1448 - auc: 0.9837 - val_loss: 0.1513 - val_auc: 0.9832 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "596/596 [==============================] - 46s 77ms/step - loss: 0.1403 - auc: 0.9844 - val_loss: 0.1895 - val_auc: 0.9770 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.1424 - auc: 0.9841\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.1424 - auc: 0.9841 - val_loss: 0.1634 - val_auc: 0.9837 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.1088 - auc: 0.9897 - val_loss: 0.1274 - val_auc: 0.9862 - lr: 2.0000e-04\n",
            "Epoch 35/50\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.0996 - auc: 0.9908 - val_loss: 0.1296 - val_auc: 0.9860 - lr: 2.0000e-04\n",
            "Epoch 36/50\n",
            "596/596 [==============================] - 47s 80ms/step - loss: 0.0954 - auc: 0.9913 - val_loss: 0.1267 - val_auc: 0.9863 - lr: 2.0000e-04\n",
            "Epoch 37/50\n",
            "596/596 [==============================] - 48s 81ms/step - loss: 0.0942 - auc: 0.9918 - val_loss: 0.1272 - val_auc: 0.9868 - lr: 2.0000e-04\n",
            "Epoch 38/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.0922 - auc: 0.9919\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.0922 - auc: 0.9919 - val_loss: 0.1291 - val_auc: 0.9863 - lr: 2.0000e-04\n",
            "Epoch 39/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.0850 - auc: 0.9926 - val_loss: 0.1149 - val_auc: 0.9882 - lr: 5.0000e-05\n",
            "Epoch 40/50\n",
            "596/596 [==============================] - 48s 80ms/step - loss: 0.0832 - auc: 0.9929 - val_loss: 0.1228 - val_auc: 0.9865 - lr: 5.0000e-05\n",
            "Epoch 41/50\n",
            "596/596 [==============================] - 48s 81ms/step - loss: 0.0837 - auc: 0.9930 - val_loss: 0.1275 - val_auc: 0.9864 - lr: 5.0000e-05\n",
            "Epoch 42/50\n",
            "596/596 [==============================] - 47s 79ms/step - loss: 0.0846 - auc: 0.9928 - val_loss: 0.1174 - val_auc: 0.9884 - lr: 5.0000e-05\n",
            "Epoch 43/50\n",
            "596/596 [==============================] - 46s 78ms/step - loss: 0.0813 - auc: 0.9933 - val_loss: 0.1167 - val_auc: 0.9874 - lr: 5.0000e-05\n",
            "Epoch 44/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.0817 - auc: 0.9932Restoring model weights from the end of the best epoch: 39.\n",
            "596/596 [==============================] - 48s 81ms/step - loss: 0.0817 - auc: 0.9932 - val_loss: 0.1235 - val_auc: 0.9871 - lr: 5.0000e-05\n",
            "Epoch 44: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
        "hist = model3.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x15--g4F-VJj",
        "outputId": "f3be9207-e865-46c9-87bc-249f6ae4e4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 4s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "#make a prediction by using the model\n",
        "y_pred_4 = model3.predict(\n",
        "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
        ")\n",
        "y_pred_4 = np.reshape(y_pred_4, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAIQ7Zwp-VJj"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({'label':y_pred_4})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('trial_4_Random_GGNN.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOmayOSn-VJj"
      },
      "source": [
        "It Was better on kaggle With 0.8727 so Will go with randomOversample and try different HP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh04d2JO-VJj"
      },
      "source": [
        "## Trial 5 Using RandomOverSample to fix the Data Imbalance And Changing RGCN Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWJbWbVo-VJk",
        "outputId": "3660d0b1-d90c-4aa8-fdb1-25dbb07270c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 80)           40000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           43136       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          4224        ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            65          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 95,681\n",
            "Trainable params: 95,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'RGCN'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model4 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm9HTckp-VJk"
      },
      "outputs": [],
      "source": [
        "model4.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM3bU30u-VJk",
        "outputId": "db8cbddf-1ac3-46c3-fa5c-000c7684e115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 28s 41ms/step - loss: 0.6269 - auc: 0.6985 - val_loss: 0.6215 - val_auc: 0.7250 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.5933 - auc: 0.7400 - val_loss: 0.5849 - val_auc: 0.7530 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.5779 - auc: 0.7561 - val_loss: 0.5814 - val_auc: 0.7673 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 24s 40ms/step - loss: 0.5658 - auc: 0.7703 - val_loss: 0.5636 - val_auc: 0.7802 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 24s 40ms/step - loss: 0.5567 - auc: 0.7816 - val_loss: 0.5528 - val_auc: 0.7895 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5466 - auc: 0.7926 - val_loss: 0.5525 - val_auc: 0.7978 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5339 - auc: 0.8063 - val_loss: 0.5320 - val_auc: 0.8136 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5261 - auc: 0.8146 - val_loss: 0.5354 - val_auc: 0.8204 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5155 - auc: 0.8235 - val_loss: 0.5291 - val_auc: 0.8187 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.5109 - auc: 0.8275 - val_loss: 0.5187 - val_auc: 0.8302 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4996 - auc: 0.8363 - val_loss: 0.5101 - val_auc: 0.8324 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4925 - auc: 0.8419 - val_loss: 0.4957 - val_auc: 0.8438 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.4843 - auc: 0.8480 - val_loss: 0.4948 - val_auc: 0.8437 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.4766 - auc: 0.8533 - val_loss: 0.4723 - val_auc: 0.8574 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.4692 - auc: 0.8585 - val_loss: 0.4691 - val_auc: 0.8606 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4598 - auc: 0.8646 - val_loss: 0.4511 - val_auc: 0.8701 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.4520 - auc: 0.8698 - val_loss: 0.4419 - val_auc: 0.8768 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 24s 40ms/step - loss: 0.4420 - auc: 0.8759 - val_loss: 0.4441 - val_auc: 0.8772 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.4399 - auc: 0.8770 - val_loss: 0.4261 - val_auc: 0.8851 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 24s 40ms/step - loss: 0.4295 - auc: 0.8831 - val_loss: 0.4344 - val_auc: 0.8877 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.4201 - auc: 0.8884\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.4201 - auc: 0.8884 - val_loss: 0.4278 - val_auc: 0.8845 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4006 - auc: 0.8991 - val_loss: 0.3990 - val_auc: 0.8995 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 26s 44ms/step - loss: 0.3925 - auc: 0.9031 - val_loss: 0.3889 - val_auc: 0.9056 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3914 - auc: 0.9036 - val_loss: 0.3901 - val_auc: 0.9053 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - ETA: 0s - loss: 0.3867 - auc: 0.9060\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.3867 - auc: 0.9060 - val_loss: 0.3990 - val_auc: 0.9028 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "596/596 [==============================] - 24s 40ms/step - loss: 0.3801 - auc: 0.9093 - val_loss: 0.3805 - val_auc: 0.9088 - lr: 5.0000e-05\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3795 - auc: 0.9095 - val_loss: 0.3874 - val_auc: 0.9056 - lr: 5.0000e-05\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.3792 - auc: 0.9096 - val_loss: 0.3716 - val_auc: 0.9134 - lr: 5.0000e-05\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.3761 - auc: 0.9110 - val_loss: 0.3878 - val_auc: 0.9048 - lr: 5.0000e-05\n",
            "Epoch 30/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3765 - auc: 0.9108 - val_loss: 0.3814 - val_auc: 0.9087 - lr: 5.0000e-05\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.3758 - auc: 0.9112 - val_loss: 0.3778 - val_auc: 0.9102 - lr: 5.0000e-05\n",
            "Epoch 32/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3768 - auc: 0.9107 - val_loss: 0.3791 - val_auc: 0.9096 - lr: 5.0000e-05\n",
            "Epoch 33/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.3771 - auc: 0.9104Restoring model weights from the end of the best epoch: 28.\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.3771 - auc: 0.9105 - val_loss: 0.3727 - val_auc: 0.9128 - lr: 5.0000e-05\n",
            "Epoch 33: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
        "hist = model4.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne1zQVgg-VJk"
      },
      "source": [
        "Not That Great the GGNN Was better, But lets try the other HP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BgL3DT--VJk"
      },
      "source": [
        "## Trial 6 Using RandomOverSample to fix the Data Imbalance And Changing RGAT Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SFgQ1qO-VJk",
        "outputId": "3892e2c8-3e80-405e-8e80-553f0235e876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 80)           40000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 32)           43520       ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 32)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          4224        ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 64)           8256        ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            65          ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 96,065\n",
            "Trainable params: 96,065\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'RGAT'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "params[\"num_heads\"] = 8\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model5 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model5.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoDQe9Hp-VJk",
        "outputId": "b8bf443f-bd75-419f-edce-2cf7dbed7b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 43s 58ms/step - loss: 0.6312 - auc: 0.6944 - val_loss: 0.6091 - val_auc: 0.7334 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.5983 - auc: 0.7382 - val_loss: 0.5933 - val_auc: 0.7455 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.5806 - auc: 0.7590 - val_loss: 0.5704 - val_auc: 0.7718 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.5572 - auc: 0.7838 - val_loss: 0.5558 - val_auc: 0.7879 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.5385 - auc: 0.8020 - val_loss: 0.5359 - val_auc: 0.8041 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.5205 - auc: 0.8171 - val_loss: 0.5137 - val_auc: 0.8236 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.5103 - auc: 0.8263 - val_loss: 0.5060 - val_auc: 0.8323 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.4943 - auc: 0.8389 - val_loss: 0.4810 - val_auc: 0.8503 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.4808 - auc: 0.8489 - val_loss: 0.4706 - val_auc: 0.8592 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.4655 - auc: 0.8600 - val_loss: 0.4708 - val_auc: 0.8646 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 32s 54ms/step - loss: 0.4527 - auc: 0.8687 - val_loss: 0.4527 - val_auc: 0.8778 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.4404 - auc: 0.8767 - val_loss: 0.4439 - val_auc: 0.8752 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 35s 59ms/step - loss: 0.4293 - auc: 0.8835 - val_loss: 0.4131 - val_auc: 0.8972 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 35s 58ms/step - loss: 0.4191 - auc: 0.8895 - val_loss: 0.4149 - val_auc: 0.8950 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.4086 - auc: 0.8955 - val_loss: 0.3935 - val_auc: 0.9048 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 35s 59ms/step - loss: 0.3971 - auc: 0.9015 - val_loss: 0.3935 - val_auc: 0.9046 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.3855 - auc: 0.9073\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3855 - auc: 0.9073 - val_loss: 0.3962 - val_auc: 0.9130 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 34s 58ms/step - loss: 0.3599 - auc: 0.9198 - val_loss: 0.3533 - val_auc: 0.9231 - lr: 2.0000e-04\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3497 - auc: 0.9244 - val_loss: 0.3445 - val_auc: 0.9280 - lr: 2.0000e-04\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3469 - auc: 0.9254 - val_loss: 0.3453 - val_auc: 0.9265 - lr: 2.0000e-04\n",
            "Epoch 21/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3394 - auc: 0.9290 - val_loss: 0.3423 - val_auc: 0.9277 - lr: 2.0000e-04\n",
            "Epoch 22/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3418 - auc: 0.9276 - val_loss: 0.3335 - val_auc: 0.9316 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 34s 56ms/step - loss: 0.3364 - auc: 0.9299 - val_loss: 0.3384 - val_auc: 0.9287 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3326 - auc: 0.9315 - val_loss: 0.3261 - val_auc: 0.9338 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3312 - auc: 0.9320 - val_loss: 0.3300 - val_auc: 0.9329 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.3279 - auc: 0.9333\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3280 - auc: 0.9332 - val_loss: 0.3326 - val_auc: 0.9313 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 34s 58ms/step - loss: 0.3244 - auc: 0.9347 - val_loss: 0.3261 - val_auc: 0.9344 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 34s 58ms/step - loss: 0.3209 - auc: 0.9361 - val_loss: 0.3245 - val_auc: 0.9346 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3170 - auc: 0.9376 - val_loss: 0.3115 - val_auc: 0.9394 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3131 - auc: 0.9392 - val_loss: 0.3160 - val_auc: 0.9384 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 34s 58ms/step - loss: 0.3158 - auc: 0.9380 - val_loss: 0.3147 - val_auc: 0.9380 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3138 - auc: 0.9387 - val_loss: 0.3151 - val_auc: 0.9387 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "596/596 [==============================] - 33s 54ms/step - loss: 0.3159 - auc: 0.9379 - val_loss: 0.3136 - val_auc: 0.9389 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3137 - auc: 0.9388 - val_loss: 0.3095 - val_auc: 0.9402 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3101 - auc: 0.9402 - val_loss: 0.3053 - val_auc: 0.9422 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3098 - auc: 0.9402 - val_loss: 0.3140 - val_auc: 0.9384 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "596/596 [==============================] - 34s 56ms/step - loss: 0.3084 - auc: 0.9408 - val_loss: 0.3061 - val_auc: 0.9422 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3046 - auc: 0.9421 - val_loss: 0.2998 - val_auc: 0.9440 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3044 - auc: 0.9422 - val_loss: 0.3100 - val_auc: 0.9401 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.3072 - auc: 0.9411 - val_loss: 0.3007 - val_auc: 0.9442 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3025 - auc: 0.9427 - val_loss: 0.3084 - val_auc: 0.9405 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.3029 - auc: 0.9427 - val_loss: 0.2971 - val_auc: 0.9444 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3005 - auc: 0.9435 - val_loss: 0.2971 - val_auc: 0.9461 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.3004 - auc: 0.9436 - val_loss: 0.2919 - val_auc: 0.9466 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.2990 - auc: 0.9440 - val_loss: 0.2972 - val_auc: 0.9442 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "596/596 [==============================] - 34s 56ms/step - loss: 0.2983 - auc: 0.9443 - val_loss: 0.3060 - val_auc: 0.9431 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "596/596 [==============================] - 33s 55ms/step - loss: 0.2953 - auc: 0.9454 - val_loss: 0.2923 - val_auc: 0.9461 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "596/596 [==============================] - 34s 58ms/step - loss: 0.2951 - auc: 0.9455 - val_loss: 0.2898 - val_auc: 0.9475 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "596/596 [==============================] - 34s 57ms/step - loss: 0.2953 - auc: 0.9455 - val_loss: 0.3006 - val_auc: 0.9431 - lr: 1.0000e-04\n",
            "Epoch 50/50\n",
            "596/596 [==============================] - 33s 56ms/step - loss: 0.2933 - auc: 0.9459 - val_loss: 0.2875 - val_auc: 0.9480 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.0001)\n",
        "hist = model5.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQGKOUpv-VJl",
        "outputId": "4bf59e22-0ec9-4c1c-c773-125599560594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 4s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "#make a prediction\n",
        "y_pred_5 = model5.predict(\n",
        "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
        ")\n",
        "y_pred_5 = np.reshape(y_pred_5, -1)\n",
        "submission = pd.DataFrame({'label':y_pred_5})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('trial_6_RGAT.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sRlXtBb-VJl"
      },
      "source": [
        "Still not better, Lets Continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhtMPp7--VJl"
      },
      "source": [
        "## Trial 7 Using RandomOverSample to fix the Data Imbalance And Changing RGIN Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVh6BlaA-VJl",
        "outputId": "6fefef5d-2f76-4ab6-b155-a1cd5d948c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 80)           40000       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           86144       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 128)          4224        ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 64)           8256        ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 1)            65          ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 138,689\n",
            "Trainable params: 138,689\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'RGIN'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "params[\"num_aggr_MLP_hidden_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model6 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model6.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "model6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7kGTLLR-VJl",
        "outputId": "5431ada5-808a-4df5-e96e-52944b99929c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 49s 73ms/step - loss: 0.6641 - auc: 0.6296 - val_loss: 0.6462 - val_auc: 0.6596 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 41s 68ms/step - loss: 0.6334 - auc: 0.6862 - val_loss: 0.6519 - val_auc: 0.6951 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.6178 - auc: 0.7104 - val_loss: 0.6169 - val_auc: 0.7211 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 39s 66ms/step - loss: 0.6118 - auc: 0.7195 - val_loss: 0.6098 - val_auc: 0.7231 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 39s 66ms/step - loss: 0.6101 - auc: 0.7221 - val_loss: 0.6076 - val_auc: 0.7297 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 39s 65ms/step - loss: 0.6063 - auc: 0.7274 - val_loss: 0.6035 - val_auc: 0.7306 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 39s 66ms/step - loss: 0.5941 - auc: 0.7396 - val_loss: 0.5956 - val_auc: 0.7450 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 40s 68ms/step - loss: 0.5914 - auc: 0.7450 - val_loss: 0.5878 - val_auc: 0.7563 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5825 - auc: 0.7548 - val_loss: 0.5817 - val_auc: 0.7576 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5813 - auc: 0.7541 - val_loss: 0.5813 - val_auc: 0.7571 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5800 - auc: 0.7571 - val_loss: 0.5843 - val_auc: 0.7658 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5779 - auc: 0.7596 - val_loss: 0.5801 - val_auc: 0.7662 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 40s 66ms/step - loss: 0.5711 - auc: 0.7676 - val_loss: 0.5791 - val_auc: 0.7615 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 41s 68ms/step - loss: 0.5678 - auc: 0.7727 - val_loss: 0.5677 - val_auc: 0.7780 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5699 - auc: 0.7699 - val_loss: 0.5726 - val_auc: 0.7714 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.6019 - auc: 0.7346\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 40s 68ms/step - loss: 0.6019 - auc: 0.7346 - val_loss: 0.5997 - val_auc: 0.7339 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 39s 66ms/step - loss: 0.5858 - auc: 0.7502 - val_loss: 0.5818 - val_auc: 0.7521 - lr: 2.0000e-04\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - ETA: 0s - loss: 0.5785 - auc: 0.7604\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "596/596 [==============================] - 40s 68ms/step - loss: 0.5785 - auc: 0.7604 - val_loss: 0.5795 - val_auc: 0.7590 - lr: 2.0000e-04\n",
            "Epoch 19/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.5742 - auc: 0.7666Restoring model weights from the end of the best epoch: 14.\n",
            "596/596 [==============================] - 40s 67ms/step - loss: 0.5742 - auc: 0.7666 - val_loss: 0.5737 - val_auc: 0.7665 - lr: 1.0000e-04\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.0001)\n",
        "hist = model6.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-HCmhQ-VJl"
      },
      "source": [
        "57.4% AUC And 76.65% Validation_AUC\n",
        "\n",
        "\n",
        "Ouch, Moving on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp_cttii-VJl"
      },
      "source": [
        "## Trial 8 Using RandomOverSample to fix the Data Imbalance And Changing GNN-Edge-MLP Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-RoNlJ8-VJl",
        "outputId": "c8c8080d-b83d-4036-f969-eb07354be54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_4/StatefulPartitionedCall:0', description=\"created by layer 'gnn_4'\")\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 80)           40000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_4 (GNN)                    (None, 32)           43136       ['embedding_4[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_4 (TFOpLa  (None, 32)          0           ['gnn_4[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 128)          4224        ['tf.math.segment_mean_4[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 64)           8256        ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 1)            65          ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 95,681\n",
            "Trainable params: 95,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'gnn_edge_mlp'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model7 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model7.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "model7.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q-lv0A7-VJm",
        "outputId": "545e7bf2-820c-4ccf-d5e0-0b0b0b8bf946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 29s 43ms/step - loss: 0.6249 - auc: 0.6992 - val_loss: 0.6098 - val_auc: 0.7366 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.5959 - auc: 0.7379 - val_loss: 0.5995 - val_auc: 0.7395 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.5848 - auc: 0.7494 - val_loss: 0.5796 - val_auc: 0.7582 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 24s 41ms/step - loss: 0.5693 - auc: 0.7664 - val_loss: 0.5645 - val_auc: 0.7782 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.5580 - auc: 0.7787 - val_loss: 0.5602 - val_auc: 0.7921 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.5420 - auc: 0.7956 - val_loss: 0.5497 - val_auc: 0.8006 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.5307 - auc: 0.8087 - val_loss: 0.5203 - val_auc: 0.8196 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5175 - auc: 0.8207 - val_loss: 0.5182 - val_auc: 0.8254 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.5065 - auc: 0.8309 - val_loss: 0.5130 - val_auc: 0.8283 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4965 - auc: 0.8385 - val_loss: 0.5008 - val_auc: 0.8354 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4886 - auc: 0.8446 - val_loss: 0.4886 - val_auc: 0.8514 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4792 - auc: 0.8516 - val_loss: 0.4743 - val_auc: 0.8559 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4705 - auc: 0.8573 - val_loss: 0.4663 - val_auc: 0.8609 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.4650 - auc: 0.8608 - val_loss: 0.4695 - val_auc: 0.8649 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.4585 - auc: 0.8653\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4584 - auc: 0.8653 - val_loss: 0.4869 - val_auc: 0.8581 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4368 - auc: 0.8786 - val_loss: 0.4485 - val_auc: 0.8722 - lr: 2.0000e-04\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 26s 43ms/step - loss: 0.4297 - auc: 0.8827 - val_loss: 0.4415 - val_auc: 0.8786 - lr: 2.0000e-04\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4273 - auc: 0.8841 - val_loss: 0.4460 - val_auc: 0.8724 - lr: 2.0000e-04\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 26s 43ms/step - loss: 0.4244 - auc: 0.8857 - val_loss: 0.4385 - val_auc: 0.8777 - lr: 2.0000e-04\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4218 - auc: 0.8874 - val_loss: 0.4363 - val_auc: 0.8787 - lr: 2.0000e-04\n",
            "Epoch 21/50\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.4196 - auc: 0.8884 - val_loss: 0.4343 - val_auc: 0.8797 - lr: 2.0000e-04\n",
            "Epoch 22/50\n",
            "596/596 [==============================] - 25s 43ms/step - loss: 0.4133 - auc: 0.8919 - val_loss: 0.4272 - val_auc: 0.8840 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4138 - auc: 0.8917 - val_loss: 0.4328 - val_auc: 0.8809 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4132 - auc: 0.8917 - val_loss: 0.4207 - val_auc: 0.8877 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4101 - auc: 0.8935 - val_loss: 0.4321 - val_auc: 0.8816 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "596/596 [==============================] - ETA: 0s - loss: 0.4101 - auc: 0.8936\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4101 - auc: 0.8936 - val_loss: 0.4293 - val_auc: 0.8829 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4045 - auc: 0.8964 - val_loss: 0.4222 - val_auc: 0.8869 - lr: 5.0000e-05\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.4006 - auc: 0.8987 - val_loss: 0.4192 - val_auc: 0.8878 - lr: 5.0000e-05\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4020 - auc: 0.8979 - val_loss: 0.4153 - val_auc: 0.8907 - lr: 5.0000e-05\n",
            "Epoch 30/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4009 - auc: 0.8984 - val_loss: 0.4161 - val_auc: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.4026 - auc: 0.8975 - val_loss: 0.4218 - val_auc: 0.8865 - lr: 5.0000e-05\n",
            "Epoch 32/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4023 - auc: 0.8977 - val_loss: 0.4148 - val_auc: 0.8908 - lr: 5.0000e-05\n",
            "Epoch 33/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4019 - auc: 0.8979 - val_loss: 0.4131 - val_auc: 0.8918 - lr: 5.0000e-05\n",
            "Epoch 34/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3970 - auc: 0.9004 - val_loss: 0.4183 - val_auc: 0.8887 - lr: 5.0000e-05\n",
            "Epoch 35/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.4020 - auc: 0.8978 - val_loss: 0.4173 - val_auc: 0.8893 - lr: 5.0000e-05\n",
            "Epoch 36/50\n",
            "596/596 [==============================] - 25s 41ms/step - loss: 0.3982 - auc: 0.8999 - val_loss: 0.4178 - val_auc: 0.8890 - lr: 5.0000e-05\n",
            "Epoch 37/50\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3965 - auc: 0.9007 - val_loss: 0.4196 - val_auc: 0.8887 - lr: 5.0000e-05\n",
            "Epoch 38/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.3983 - auc: 0.8997Restoring model weights from the end of the best epoch: 33.\n",
            "596/596 [==============================] - 25s 42ms/step - loss: 0.3985 - auc: 0.8996 - val_loss: 0.4255 - val_auc: 0.8848 - lr: 5.0000e-05\n",
            "Epoch 38: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
        "hist = model7.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05s9LVJO-VJm"
      },
      "source": [
        "Better than the previous one but will try to get a better one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfGxCujl-VJm"
      },
      "source": [
        "## Trial 9 Using RandomOverSample to fix the Data Imbalance And Changing GNN-FiLM Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwscM28--VJm",
        "outputId": "bbe64b80-c13a-42ec-f28e-b4ac82a6d917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_5/StatefulPartitionedCall:0', description=\"created by layer 'gnn_5'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_18[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 80)           40000       ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_5 (GNN)                    (None, 32)           80000       ['embedding_5[0][0]',            \n",
            "                                                                  'input_17[0][0]',               \n",
            "                                                                  'input_18[0][0]',               \n",
            "                                                                  'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 32)          0           ['gnn_5[0][0]',                  \n",
            " mbda)                                                            'input_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 128)          4224        ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 64)           8256        ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 1)            65          ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 132,545\n",
            "Trainable params: 132,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'GNN_FiLM'\n",
        "params[\"hidden_dim\"] = 32\n",
        "params[\"num_layers\"] = 6\n",
        "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model8 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model8.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "model8.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di0imaf9-VJm",
        "outputId": "74c6839d-8354-483f-9572-d0f6272e89c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 37s 55ms/step - loss: 0.6192 - auc: 0.7128 - val_loss: 0.5644 - val_auc: 0.7812 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 32s 54ms/step - loss: 0.5419 - auc: 0.8028 - val_loss: 0.5316 - val_auc: 0.8188 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 31s 53ms/step - loss: 0.5026 - auc: 0.8353 - val_loss: 0.5897 - val_auc: 0.8235 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 31s 52ms/step - loss: 0.4597 - auc: 0.8654 - val_loss: 0.4263 - val_auc: 0.8873 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 31s 52ms/step - loss: 0.3988 - auc: 0.9006 - val_loss: 0.3842 - val_auc: 0.9134 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.3534 - auc: 0.9217 - val_loss: 0.3400 - val_auc: 0.9273 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.3159 - auc: 0.9365 - val_loss: 0.3119 - val_auc: 0.9389 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.2872 - auc: 0.9466 - val_loss: 0.2713 - val_auc: 0.9511 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.2646 - auc: 0.9534 - val_loss: 0.2514 - val_auc: 0.9575 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.2451 - auc: 0.9594 - val_loss: 0.2796 - val_auc: 0.9499 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.2278 - auc: 0.9643 - val_loss: 0.2455 - val_auc: 0.9597 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.2168 - auc: 0.9668 - val_loss: 0.2277 - val_auc: 0.9632 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.2080 - auc: 0.9691 - val_loss: 0.2286 - val_auc: 0.9679 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.1909 - auc: 0.9725 - val_loss: 0.2270 - val_auc: 0.9635 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.1885 - auc: 0.9740 - val_loss: 0.1925 - val_auc: 0.9718 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.1662 - auc: 0.9784 - val_loss: 0.1845 - val_auc: 0.9759 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.1608 - auc: 0.9793 - val_loss: 0.1806 - val_auc: 0.9736 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.1564 - auc: 0.9800 - val_loss: 0.1586 - val_auc: 0.9789 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.1445 - auc: 0.9820 - val_loss: 0.1522 - val_auc: 0.9814 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.1429 - auc: 0.9826 - val_loss: 0.1755 - val_auc: 0.9755 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.1385 - auc: 0.9835\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.1385 - auc: 0.9835 - val_loss: 0.1716 - val_auc: 0.9783 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.1001 - auc: 0.9896 - val_loss: 0.1055 - val_auc: 0.9875 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0847 - auc: 0.9913 - val_loss: 0.1115 - val_auc: 0.9868 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0779 - auc: 0.9923 - val_loss: 0.1033 - val_auc: 0.9877 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0772 - auc: 0.9926 - val_loss: 0.1012 - val_auc: 0.9886 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0730 - auc: 0.9928 - val_loss: 0.0979 - val_auc: 0.9887 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0689 - auc: 0.9934 - val_loss: 0.0910 - val_auc: 0.9897 - lr: 2.0000e-04\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0686 - auc: 0.9938 - val_loss: 0.0901 - val_auc: 0.9893 - lr: 2.0000e-04\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0650 - auc: 0.9941 - val_loss: 0.0901 - val_auc: 0.9904 - lr: 2.0000e-04\n",
            "Epoch 30/50\n",
            "596/596 [==============================] - ETA: 0s - loss: 0.0623 - auc: 0.9945\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0623 - auc: 0.9945 - val_loss: 0.0934 - val_auc: 0.9902 - lr: 2.0000e-04\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0582 - auc: 0.9949 - val_loss: 0.0851 - val_auc: 0.9908 - lr: 5.0000e-05\n",
            "Epoch 32/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0546 - auc: 0.9954 - val_loss: 0.0898 - val_auc: 0.9903 - lr: 5.0000e-05\n",
            "Epoch 33/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0526 - auc: 0.9956 - val_loss: 0.0846 - val_auc: 0.9909 - lr: 5.0000e-05\n",
            "Epoch 34/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0518 - auc: 0.9957 - val_loss: 0.0940 - val_auc: 0.9898 - lr: 5.0000e-05\n",
            "Epoch 35/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0519 - auc: 0.9957 - val_loss: 0.0851 - val_auc: 0.9905 - lr: 5.0000e-05\n",
            "Epoch 36/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0514 - auc: 0.9957 - val_loss: 0.0829 - val_auc: 0.9909 - lr: 5.0000e-05\n",
            "Epoch 37/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0509 - auc: 0.9958 - val_loss: 0.0837 - val_auc: 0.9919 - lr: 5.0000e-05\n",
            "Epoch 38/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0504 - auc: 0.9959 - val_loss: 0.0828 - val_auc: 0.9909 - lr: 5.0000e-05\n",
            "Epoch 39/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0504 - auc: 0.9959 - val_loss: 0.0851 - val_auc: 0.9908 - lr: 5.0000e-05\n",
            "Epoch 40/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0494 - auc: 0.9961 - val_loss: 0.0848 - val_auc: 0.9917 - lr: 5.0000e-05\n",
            "Epoch 41/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0487 - auc: 0.9961 - val_loss: 0.0804 - val_auc: 0.9909 - lr: 5.0000e-05\n",
            "Epoch 42/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0463 - auc: 0.9966 - val_loss: 0.0840 - val_auc: 0.9915 - lr: 5.0000e-05\n",
            "Epoch 43/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0468 - auc: 0.9964 - val_loss: 0.0842 - val_auc: 0.9913 - lr: 5.0000e-05\n",
            "Epoch 44/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0474 - auc: 0.9963 - val_loss: 0.0795 - val_auc: 0.9921 - lr: 5.0000e-05\n",
            "Epoch 45/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0449 - auc: 0.9966 - val_loss: 0.0916 - val_auc: 0.9896 - lr: 5.0000e-05\n",
            "Epoch 46/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0463 - auc: 0.9966 - val_loss: 0.0799 - val_auc: 0.9916 - lr: 5.0000e-05\n",
            "Epoch 47/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0459 - auc: 0.9965 - val_loss: 0.0841 - val_auc: 0.9907 - lr: 5.0000e-05\n",
            "Epoch 48/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0445 - auc: 0.9967 - val_loss: 0.0777 - val_auc: 0.9926 - lr: 5.0000e-05\n",
            "Epoch 49/50\n",
            "596/596 [==============================] - 30s 51ms/step - loss: 0.0436 - auc: 0.9968 - val_loss: 0.0756 - val_auc: 0.9923 - lr: 5.0000e-05\n",
            "Epoch 50/50\n",
            "596/596 [==============================] - 30s 50ms/step - loss: 0.0450 - auc: 0.9967 - val_loss: 0.0861 - val_auc: 0.9903 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=0.00005)\n",
        "hist = model8.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn1zzs12-VJm",
        "outputId": "aa6d6341-bb16-452d-c281-bd2d4728ec0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 3s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "#make a prediction\n",
        "y_pred_8 = model8.predict(\n",
        "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
        ")\n",
        "y_pred_8 = np.reshape(y_pred_8, -1)\n",
        "submission = pd.DataFrame({'label':y_pred_8})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('trial_9_film.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8U7buKs-VJm"
      },
      "source": [
        "It got a score of 88.37% on Kaggle and that is by far the best accuracy I Got, but we will try onc last Trial before call an End"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ1ZeaKN-VJn"
      },
      "source": [
        "## Trial 10 Using RandomOverSample to fix the Data Imbalance And Using ggnn Hyperparameters and Changing some Other Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGXzVuVM-VJn",
        "outputId": "e2ba5d01-746a-4b23-f182-63359624d7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, 80)           40000       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  ()                  0           ['tf.math.reduce_max_6[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_6 (GNN)                    (None, 128)          1049600     ['embedding_6[0][0]',            \n",
            "                                                                  'input_20[0][0]',               \n",
            "                                                                  'input_21[0][0]',               \n",
            "                                                                  'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 128)         0           ['gnn_6[0][0]',                  \n",
            " mbda)                                                            'input_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          16512       ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 64)           8256        ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 1)            65          ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,114,433\n",
            "Trainable params: 1,114,433\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "embeded = Embedding(tokenizer3.num_words, 80)(data)\n",
        "\n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "params[\"hidden_dim\"] = 128\n",
        "params[\"num_layers\"] = 6\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params) \n",
        "\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )\n",
        "\n",
        "l1 = Dense(128,activation='relu')(avg)\n",
        "l2 = Dense(64,activation='relu')(l1)\n",
        "pred = Dense(1, activation='sigmoid')(l2)\n",
        "\n",
        "\n",
        "model9 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model9.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "model9.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0YmvnQNb-VJn",
        "outputId": "40fcf852-50e0-43df-b173-fa0fb842a9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "596/596 [==============================] - 218s 359ms/step - loss: 0.6268 - auc: 0.7005 - val_loss: 0.5874 - val_auc: 0.7582 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "596/596 [==============================] - 212s 356ms/step - loss: 0.5363 - auc: 0.8073 - val_loss: 0.5010 - val_auc: 0.8416 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "596/596 [==============================] - 214s 358ms/step - loss: 0.4762 - auc: 0.8535 - val_loss: 0.4662 - val_auc: 0.8599 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "596/596 [==============================] - 213s 357ms/step - loss: 0.4393 - auc: 0.8775 - val_loss: 0.4173 - val_auc: 0.8906 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "596/596 [==============================] - 213s 358ms/step - loss: 0.3964 - auc: 0.9015 - val_loss: 0.4298 - val_auc: 0.8968 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "596/596 [==============================] - 212s 355ms/step - loss: 0.3532 - auc: 0.9223 - val_loss: 0.3679 - val_auc: 0.9238 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "596/596 [==============================] - 212s 356ms/step - loss: 0.3162 - auc: 0.9378 - val_loss: 0.3107 - val_auc: 0.9420 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "596/596 [==============================] - 212s 356ms/step - loss: 0.2836 - auc: 0.9494 - val_loss: 0.3118 - val_auc: 0.9465 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "596/596 [==============================] - 212s 356ms/step - loss: 0.2550 - auc: 0.9583 - val_loss: 0.2510 - val_auc: 0.9593 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "596/596 [==============================] - 216s 362ms/step - loss: 0.2180 - auc: 0.9685 - val_loss: 0.2200 - val_auc: 0.9688 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "596/596 [==============================] - 221s 371ms/step - loss: 0.1963 - auc: 0.9739 - val_loss: 0.2238 - val_auc: 0.9709 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "596/596 [==============================] - 218s 365ms/step - loss: 0.1810 - auc: 0.9769 - val_loss: 0.1935 - val_auc: 0.9752 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "596/596 [==============================] - 219s 368ms/step - loss: 0.1614 - auc: 0.9809 - val_loss: 0.1657 - val_auc: 0.9804 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "596/596 [==============================] - 219s 368ms/step - loss: 0.1487 - auc: 0.9834 - val_loss: 0.1714 - val_auc: 0.9796 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "596/596 [==============================] - 218s 366ms/step - loss: 0.1313 - auc: 0.9865 - val_loss: 0.1521 - val_auc: 0.9814 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "596/596 [==============================] - 218s 366ms/step - loss: 0.1199 - auc: 0.9883 - val_loss: 0.1380 - val_auc: 0.9862 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "596/596 [==============================] - 214s 359ms/step - loss: 0.1200 - auc: 0.9884 - val_loss: 0.1628 - val_auc: 0.9813 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "596/596 [==============================] - 215s 361ms/step - loss: 0.1249 - auc: 0.9875 - val_loss: 0.1812 - val_auc: 0.9767 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "596/596 [==============================] - 215s 360ms/step - loss: 0.1089 - auc: 0.9901 - val_loss: 0.1215 - val_auc: 0.9870 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "596/596 [==============================] - 214s 358ms/step - loss: 0.1037 - auc: 0.9910 - val_loss: 0.1334 - val_auc: 0.9859 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "596/596 [==============================] - 216s 363ms/step - loss: 0.1038 - auc: 0.9907 - val_loss: 0.1340 - val_auc: 0.9865 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.0961 - auc: 0.9917\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "596/596 [==============================] - 217s 364ms/step - loss: 0.0961 - auc: 0.9917 - val_loss: 0.1370 - val_auc: 0.9861 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "596/596 [==============================] - 217s 364ms/step - loss: 0.0582 - auc: 0.9960 - val_loss: 0.0837 - val_auc: 0.9925 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "596/596 [==============================] - 221s 371ms/step - loss: 0.0450 - auc: 0.9971 - val_loss: 0.0819 - val_auc: 0.9924 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "596/596 [==============================] - 215s 361ms/step - loss: 0.0393 - auc: 0.9978 - val_loss: 0.0792 - val_auc: 0.9927 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "596/596 [==============================] - 215s 361ms/step - loss: 0.0401 - auc: 0.9976 - val_loss: 0.0731 - val_auc: 0.9937 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "596/596 [==============================] - 216s 362ms/step - loss: 0.0334 - auc: 0.9983 - val_loss: 0.0656 - val_auc: 0.9938 - lr: 2.0000e-04\n",
            "Epoch 28/50\n",
            "596/596 [==============================] - 216s 362ms/step - loss: 0.0345 - auc: 0.9983 - val_loss: 0.0729 - val_auc: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 29/50\n",
            "596/596 [==============================] - 214s 359ms/step - loss: 0.0306 - auc: 0.9985 - val_loss: 0.0737 - val_auc: 0.9931 - lr: 2.0000e-04\n",
            "Epoch 30/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.0314 - auc: 0.9985\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "596/596 [==============================] - 215s 361ms/step - loss: 0.0315 - auc: 0.9985 - val_loss: 0.0719 - val_auc: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 31/50\n",
            "596/596 [==============================] - 219s 368ms/step - loss: 0.0254 - auc: 0.9990 - val_loss: 0.0702 - val_auc: 0.9931 - lr: 5.0000e-05\n",
            "Epoch 32/50\n",
            "595/596 [============================>.] - ETA: 0s - loss: 0.0237 - auc: 0.9991Restoring model weights from the end of the best epoch: 27.\n",
            "596/596 [==============================] - 215s 360ms/step - loss: 0.0237 - auc: 0.9991 - val_loss: 0.0738 - val_auc: 0.9928 - lr: 5.0000e-05\n",
            "Epoch 32: early stopping\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_batchs = math.ceil(len(training_set4) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set4) / batch_size)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=0.00005)\n",
        "hist = model9.fit(\n",
        "    gen_batch(\n",
        "        training_set4, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=50,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set4, batch_size=64, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        "    verbose=1,callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTU6h2WM-VJn",
        "outputId": "5ad371f1-0a97-4cbf-e42b-a22b6a93b8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 20s 101ms/step\n"
          ]
        }
      ],
      "source": [
        "#make a prediction\n",
        "y_pred_9 = model9.predict(\n",
        "    gen_batch(testing_set, batch_size=64, shuffle=False)\n",
        ")\n",
        "y_pred_9 = np.reshape(y_pred_9, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkL8mcMt-VJn"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({'label':y_pred_9})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('trial_10_GGNNhyper.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7zOufq5-VJn"
      },
      "source": [
        "When I Saw the Result on Kaggle it is obvious that it overfitted the data so the generalization Error was large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbuWoA6-VJn"
      },
      "source": [
        "# **Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7rRUw7s-VJn"
      },
      "source": [
        "After Doing the 10 Trials with Different Hyperparameters The Best one I Got with low Generalization Error was The 9th Trial Using GNN-FiLM with Test Accuracy = 88.37% And maybe I Could Get better result with fine tunning more but we will keep it for now "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nsEj39ikmhxJ",
        "Sudgalm0ni5u",
        "gCpYUw7KsCXV",
        "ju9rslKkunTm",
        "OmYsFtefvWvE",
        "W30yR6DBujwV",
        "iF9avmoRwY1q",
        "kbxr60pV-VJg",
        "xglDXdST-VJh",
        "fh04d2JO-VJj",
        "8BgL3DT--VJk",
        "fhtMPp7--VJl",
        "dp_cttii-VJl",
        "dfGxCujl-VJm",
        "lZ1ZeaKN-VJn",
        "RgbuWoA6-VJn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0327c0dad8fc4b9aa5a93993c0363319": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0beb302c2b9746329f7ec3a98926ba82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1fa67b224e402d97557584d3268080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c2b9e8f0f748998720e71ca7845fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4100bdce902f40ecb70c6ffa920ccb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58358e0c85a149cbaa5448717c64b4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0327c0dad8fc4b9aa5a93993c0363319",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_efd45c231402417a8f98c852e3bc38c6",
            "value": " 25024/25024 [00:02&lt;00:00, 10857.89it/s]"
          }
        },
        "5b89e71fc8d043a392b61ea493b79b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0beb302c2b9746329f7ec3a98926ba82",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4100bdce902f40ecb70c6ffa920ccb27",
            "value": 12326
          }
        },
        "5fb4cec0034d4c1db2e0e84b0ac62ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d83feb7c2640e3915e2a03654e21e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8afc8dad8e1942eca6cbd5c253e45464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd947e6cd3c43fcb31678391ecea122": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926dd136cac14f919d3275a48561c8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4960bfa9f014222b805bde80788b375",
              "IPY_MODEL_5b89e71fc8d043a392b61ea493b79b44",
              "IPY_MODEL_f8683b3a53694c82ace06cab4b5b5e91"
            ],
            "layout": "IPY_MODEL_ee6314ce05c04ee885fd220883124499"
          }
        },
        "a0e40a02cb1a47fb9da41f9b96e679ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4960bfa9f014222b805bde80788b375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb4cec0034d4c1db2e0e84b0ac62ee4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f1fa67b224e402d97557584d3268080",
            "value": "100%"
          }
        },
        "a5f274eb69c9493eadadd21b60974923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dead3d8ff34e4062bc294dc5bc9125bd",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0e40a02cb1a47fb9da41f9b96e679ef",
            "value": 25024
          }
        },
        "d9bea941346e4c3bb3aab74ee452a751": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd947e6cd3c43fcb31678391ecea122",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_18c2b9e8f0f748998720e71ca7845fcc",
            "value": "100%"
          }
        },
        "dead3d8ff34e4062bc294dc5bc9125bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa20e722483401ba3819c0661f3ce55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee6314ce05c04ee885fd220883124499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd45c231402417a8f98c852e3bc38c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8683b3a53694c82ace06cab4b5b5e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8afc8dad8e1942eca6cbd5c253e45464",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eaa20e722483401ba3819c0661f3ce55",
            "value": " 12326/12326 [00:01&lt;00:00, 6808.01it/s]"
          }
        },
        "fed583ccf6af4e378edc72a61d6af690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9bea941346e4c3bb3aab74ee452a751",
              "IPY_MODEL_a5f274eb69c9493eadadd21b60974923",
              "IPY_MODEL_58358e0c85a149cbaa5448717c64b4b3"
            ],
            "layout": "IPY_MODEL_88d83feb7c2640e3915e2a03654e21e9"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}